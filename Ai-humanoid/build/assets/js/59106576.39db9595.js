"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[8314],{5837:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>_,frontMatter:()=>r,metadata:()=>a,toc:()=>d});const a=JSON.parse('{"id":"Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/dataset-export-and-management","title":"dataset export and management","description":"Dataset export and management form the final critical component of the synthetic data generation pipeline in Isaac Sim. This chapter covers the processes of converting synthetic data into standard formats, organizing large datasets, implementing versioning systems, and establishing quality control measures that ensure datasets are ready for machine learning applications.","source":"@site/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/dataset-export-and-management.md","sourceDirName":"Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation","slug":"/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/dataset-export-and-management","permalink":"/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/dataset-export-and-management","draft":false,"unlisted":false,"editUrl":"https://github.com/areebayaseen15/Ai-Humanoid-textbook/edit/main/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/dataset-export-and-management.md","tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"id":"dataset-export-and-management","title":"dataset export and management","sidebar_label":"dataset export and management","sidebar_position":0},"sidebar":"tutorialSidebar","previous":{"title":"data generation pipelines","permalink":"/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/data-generation-pipelines"},"next":{"title":"domain randomization","permalink":"/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/domain-randomization"}}');var i=n(4848),s=n(8453);const r={id:"dataset-export-and-management",title:"dataset export and management",sidebar_label:"dataset export and management",sidebar_position:0},o="3.3.5 Dataset Export and Management",l={},d=[{value:"Dataset Format Conversion",id:"dataset-format-conversion",level:2},{value:"Standard Dataset Formats",id:"standard-dataset-formats",level:3},{value:"COCO Format Export",id:"coco-format-export",level:3},{value:"KITTI Format Export",id:"kitti-format-export",level:3},{value:"YOLO Format Export",id:"yolo-format-export",level:3},{value:"Data Versioning Strategies",id:"data-versioning-strategies",level:2},{value:"Git-Based Versioning",id:"git-based-versioning",level:3},{value:"DVC (Data Version Control)",id:"dvc-data-version-control",level:3},{value:"Custom Dataset Versioning System",id:"custom-dataset-versioning-system",level:3},{value:"Dataset Quality Validation",id:"dataset-quality-validation",level:2},{value:"Quality Metrics and Validation",id:"quality-metrics-and-validation",level:3},{value:"Automated Quality Assurance Pipeline",id:"automated-quality-assurance-pipeline",level:3},{value:"Storage and Organization Best Practices",id:"storage-and-organization-best-practices",level:2},{value:"Hierarchical Dataset Organization",id:"hierarchical-dataset-organization",level:3},{value:"Efficient Storage Strategies",id:"efficient-storage-strategies",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Dataset Management Best Practices",id:"dataset-management-best-practices",level:3},{value:"Export Pipeline Best Practices",id:"export-pipeline-best-practices",level:3},{value:"Conclusion",id:"conclusion",level:2}];function c(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,s.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.header,{children:(0,i.jsx)(t.h1,{id:"335-dataset-export-and-management",children:"3.3.5 Dataset Export and Management"})}),"\n",(0,i.jsx)(t.p,{children:"Dataset export and management form the final critical component of the synthetic data generation pipeline in Isaac Sim. This chapter covers the processes of converting synthetic data into standard formats, organizing large datasets, implementing versioning systems, and establishing quality control measures that ensure datasets are ready for machine learning applications."}),"\n",(0,i.jsx)(t.h2,{id:"dataset-format-conversion",children:"Dataset Format Conversion"}),"\n",(0,i.jsx)(t.h3,{id:"standard-dataset-formats",children:"Standard Dataset Formats"}),"\n",(0,i.jsx)(t.p,{children:"Isaac Sim synthetic data needs to be converted to standard formats for compatibility with machine learning frameworks and tools. The most common formats include:"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"COCO (Common Objects in Context)"}),": The most popular format for object detection, segmentation, and keypoint detection tasks."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"KITTI"}),": Commonly used for autonomous driving and 3D object detection tasks."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Pascal VOC"}),": Traditional format for object detection and classification."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"TFRecord"}),": TensorFlow's binary format for efficient data loading."]}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Yolo"}),": Simple text-based format popular for real-time object detection."]}),"\n",(0,i.jsx)(t.h3,{id:"coco-format-export",children:"COCO Format Export"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'# Example: COCO format export from Isaac Sim synthetic data\nimport json\nimport os\nfrom datetime import datetime\nimport numpy as np\nfrom PIL import Image\n\nclass COCOExporter:\n    def __init__(self, output_dir):\n        self.output_dir = output_dir\n        self.images_dir = os.path.join(output_dir, "images")\n        self.annotations_dir = os.path.join(output_dir, "annotations")\n\n        # Create directories\n        os.makedirs(self.images_dir, exist_ok=True)\n        os.makedirs(self.annotations_dir, exist_ok=True)\n\n    def export_dataset(self, synthetic_data, dataset_name="synthetic_dataset"):\n        """Export synthetic data to COCO format"""\n\n        # Initialize COCO structure\n        coco_data = {\n            "info": self._create_info(dataset_name),\n            "licenses": self._create_licenses(),\n            "categories": self._create_categories(),\n            "images": [],\n            "annotations": []\n        }\n\n        # Process each sample\n        annotation_id = 1\n        for sample_idx, sample in enumerate(synthetic_data):\n            # Add image information\n            image_info = self._create_image_info(sample, sample_idx)\n            coco_data["images"].append(image_info)\n\n            # Add annotations for this image\n            for obj in sample.get("objects", []):\n                annotation = self._create_annotation(\n                    obj, sample_idx, annotation_id\n                )\n                coco_data["annotations"].append(annotation)\n                annotation_id += 1\n\n            # Save image\n            self._save_image(sample["rgb_image"], sample_idx)\n\n        # Save COCO annotation file\n        self._save_coco_annotations(coco_data, dataset_name)\n\n        return coco_data\n\n    def _create_info(self, dataset_name):\n        """Create dataset info section"""\n        return {\n            "description": f"Synthetic dataset generated with Isaac Sim: {dataset_name}",\n            "url": "https://developer.nvidia.com/isaac-sim",\n            "version": "1.0",\n            "year": datetime.now().year,\n            "contributor": "Isaac Sim Synthetic Data Generator",\n            "date_created": datetime.now().strftime("%Y/%m/%d")\n        }\n\n    def _create_licenses(self):\n        """Create license information"""\n        return [{\n            "id": 1,\n            "name": "Synthetic Data License",\n            "url": "https://nvidia.com/license"\n        }]\n\n    def _create_categories(self):\n        """Create category definitions"""\n        # Define your object categories here\n        categories = [\n            {"id": 1, "name": "car", "supercategory": "vehicle"},\n            {"id": 2, "name": "pedestrian", "supercategory": "person"},\n            {"id": 3, "name": "bicycle", "supercategory": "vehicle"},\n            {"id": 4, "name": "traffic_sign", "supercategory": "infrastructure"},\n            {"id": 5, "name": "tree", "supercategory": "vegetation"},\n            # Add more categories as needed\n        ]\n        return categories\n\n    def _create_image_info(self, sample, image_id):\n        """Create image information entry"""\n        img = sample["rgb_image"]\n        height, width = img.shape[:2] if isinstance(img, np.ndarray) else (480, 640)\n\n        return {\n            "id": image_id,\n            "width": width,\n            "height": height,\n            "file_name": f"{image_id:06d}.jpg",\n            "license": 1,\n            "flickr_url": "",\n            "coco_url": "",\n            "date_captured": sample.get("timestamp", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))\n        }\n\n    def _create_annotation(self, obj, image_id, annotation_id):\n        """Create annotation entry for an object"""\n        # Calculate bounding box\n        bbox = self._calculate_bbox(obj)\n\n        # Calculate area\n        area = bbox[2] * bbox[3]  # width * height\n\n        # Create segmentation (polygon format)\n        segmentation = self._create_segmentation(obj)\n\n        return {\n            "id": annotation_id,\n            "image_id": image_id,\n            "category_id": obj["category_id"],\n            "segmentation": segmentation,\n            "area": area,\n            "bbox": bbox,\n            "iscrowd": 0,\n            "keypoints": obj.get("keypoints", []),\n            "num_keypoints": len(obj.get("keypoints", [])) // 3 if obj.get("keypoints") else 0\n        }\n\n    def _calculate_bbox(self, obj):\n        """Calculate bounding box from object information"""\n        if "bbox" in obj:\n            return obj["bbox"]\n\n        # If bbox not provided, calculate from mask or 3D info\n        # This is a simplified implementation\n        return [obj.get("x", 0), obj.get("y", 0),\n                obj.get("width", 50), obj.get("height", 50)]\n\n    def _create_segmentation(self, obj):\n        """Create segmentation polygon from object"""\n        # For synthetic data, we might have precise segmentation\n        # This is a simplified implementation\n        if "segmentation_polygon" in obj:\n            return [obj["segmentation_polygon"]]\n        else:\n            # Create bounding box based segmentation\n            x, y, w, h = self._calculate_bbox(obj)\n            return [[x, y, x+w, y, x+w, y+h, x, y+h]]\n\n    def _save_image(self, image, image_id):\n        """Save image to disk"""\n        image_path = os.path.join(self.images_dir, f"{image_id:06d}.jpg")\n\n        if isinstance(image, np.ndarray):\n            img = Image.fromarray(image.astype(\'uint8\'))\n            img.save(image_path, quality=95)\n        else:\n            # Assume it\'s already a file path\n            import shutil\n            shutil.copy(image, image_path)\n\n    def _save_coco_annotations(self, coco_data, dataset_name):\n        """Save COCO annotations to JSON file"""\n        annotation_path = os.path.join(\n            self.annotations_dir,\n            f"instances_{dataset_name}.json"\n        )\n\n        with open(annotation_path, \'w\') as f:\n            json.dump(coco_data, f, indent=2)\n\n# Usage example\nexporter = COCOExporter("./output/coco_dataset")\n# coco_dataset = exporter.export_dataset(synthetic_data, "warehouse_robots")\n'})}),"\n",(0,i.jsx)(t.h3,{id:"kitti-format-export",children:"KITTI Format Export"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'class KITTIExporter:\n    def __init__(self, output_dir):\n        self.output_dir = output_dir\n        self.image_dir = os.path.join(output_dir, "image_2")\n        self.label_dir = os.path.join(output_dir, "label_2")\n        self.calib_dir = os.path.join(output_dir, "calib")\n\n        # Create directories\n        os.makedirs(self.image_dir, exist_ok=True)\n        os.makedirs(self.label_dir, exist_ok=True)\n        os.makedirs(self.calib_dir, exist_ok=True)\n\n    def export_dataset(self, synthetic_data):\n        """Export to KITTI format"""\n\n        for sample_idx, sample in enumerate(synthetic_data):\n            # Save image\n            self._save_image(sample["rgb_image"], sample_idx)\n\n            # Save labels\n            self._save_labels(sample.get("objects", []), sample_idx)\n\n            # Save calibration\n            self._save_calibration(sample.get("camera_params", {}), sample_idx)\n\n    def _save_labels(self, objects, sample_idx):\n        """Save KITTI format labels"""\n        label_path = os.path.join(self.label_dir, f"{sample_idx:06d}.txt")\n\n        with open(label_path, \'w\') as f:\n            for obj in objects:\n                # KITTI format: type, truncated, occluded, alpha, bbox, dimensions, location, rotation_y\n                kitti_line = [\n                    obj.get("class_name", "DontCare"),\n                    f"{obj.get(\'truncated\', 0.0):.2f}",\n                    f"{obj.get(\'occluded\', 0)}",\n                    f"{obj.get(\'alpha\', -10):.2f}",\n                    # Bounding box (left, top, right, bottom)\n                    f"{obj[\'bbox\'][0]:.2f}",\n                    f"{obj[\'bbox\'][1]:.2f}",\n                    f"{obj[\'bbox\'][0] + obj[\'bbox\'][2]:.2f}",\n                    f"{obj[\'bbox\'][1] + obj[\'bbox\'][3]:.2f}",\n                    # Dimensions (height, width, length)\n                    f"{obj.get(\'dimensions\', [0, 0, 0])[0]:.2f}",\n                    f"{obj.get(\'dimensions\', [0, 0, 0])[1]:.2f}",\n                    f"{obj.get(\'dimensions\', [0, 0, 0])[2]:.2f}",\n                    # Location (x, y, z)\n                    f"{obj.get(\'location\', [0, 0, 0])[0]:.2f}",\n                    f"{obj.get(\'location\', [0, 0, 0])[1]:.2f}",\n                    f"{obj.get(\'location\', [0, 0, 0])[2]:.2f}",\n                    # Rotation around Y axis\n                    f"{obj.get(\'rotation_y\', 0):.2f}"\n                ]\n\n                f.write(" ".join(kitti_line) + "\\n")\n\n    def _save_calibration(self, camera_params, sample_idx):\n        """Save calibration parameters"""\n        calib_path = os.path.join(self.calib_dir, f"{sample_idx:06d}.txt")\n\n        # Default calibration matrix for a typical camera\n        calib_matrix = camera_params.get("p_rect_00", [\n            721.5377, 0.0, 609.5593, 0.0,\n            0.0, 721.5377, 172.854, 0.0,\n            0.0, 0.0, 1.0, 0.0\n        ])\n\n        with open(calib_path, \'w\') as f:\n            f.write(f"P0: {\' \'.join(map(str, calib_matrix))}\\n")\n            f.write(f"P1: {\' \'.join(map(str, calib_matrix))}\\n")\n            f.write(f"P2: {\' \'.join(map(str, calib_matrix))}\\n")\n            f.write(f"P3: {\' \'.join(map(str, calib_matrix))}\\n")\n'})}),"\n",(0,i.jsx)(t.h3,{id:"yolo-format-export",children:"YOLO Format Export"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'class YOLOExporter:\n    def __init__(self, output_dir):\n        self.output_dir = output_dir\n        self.images_dir = os.path.join(output_dir, "images")\n        self.labels_dir = os.path.join(output_dir, "labels")\n\n        os.makedirs(self.images_dir, exist_ok=True)\n        os.makedirs(self.labels_dir, exist_ok=True)\n\n    def export_dataset(self, synthetic_data, class_mapping):\n        """Export to YOLO format"""\n\n        for sample_idx, sample in enumerate(synthetic_data):\n            # Save image\n            self._save_image(sample["rgb_image"], sample_idx)\n\n            # Save YOLO format labels\n            self._save_yolo_labels(\n                sample.get("objects", []),\n                sample_idx,\n                sample["rgb_image"].shape[1],  # width\n                sample["rgb_image"].shape[0],  # height\n                class_mapping\n            )\n\n    def _save_yolo_labels(self, objects, sample_idx, img_width, img_height, class_mapping):\n        """Save labels in YOLO format (normalized coordinates)"""\n        label_path = os.path.join(self.labels_dir, f"{sample_idx:06d}.txt")\n\n        with open(label_path, \'w\') as f:\n            for obj in objects:\n                class_id = class_mapping.get(obj["class_name"], 0)\n\n                # Convert bbox to YOLO format (normalized center x, center y, width, height)\n                x_min, y_min, width, height = obj["bbox"]\n                x_center = (x_min + width / 2) / img_width\n                y_center = (y_min + height / 2) / img_height\n                norm_width = width / img_width\n                norm_height = height / img_height\n\n                # YOLO format: class_id center_x center_y width height\n                f.write(f"{class_id} {x_center:.6f} {y_center:.6f} {norm_width:.6f} {norm_height:.6f}\\n")\n'})}),"\n",(0,i.jsx)(t.h2,{id:"data-versioning-strategies",children:"Data Versioning Strategies"}),"\n",(0,i.jsx)(t.h3,{id:"git-based-versioning",children:"Git-Based Versioning"}),"\n",(0,i.jsx)(t.p,{children:"For smaller datasets, Git can be used with Git LFS for versioning:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'import subprocess\nimport os\nfrom datetime import datetime\n\nclass GitDatasetVersioner:\n    def __init__(self, dataset_dir):\n        self.dataset_dir = dataset_dir\n        self.original_dir = os.getcwd()\n\n    def initialize_repo(self):\n        """Initialize a Git repository for the dataset"""\n        os.chdir(self.dataset_dir)\n\n        # Initialize git repo\n        subprocess.run(["git", "init"], check=True)\n\n        # Configure Git LFS for large files\n        subprocess.run(["git", "lfs", "install"], check=True)\n\n        # Track common large file types\n        lfs_extensions = [\n            "*.jpg", "*.jpeg", "*.png", "*.tiff", "*.tif",\n            "*.bin", "*.ply", "*.pcd", "*.bag",\n            "*.mp4", "*.avi", "*.mov"\n        ]\n\n        for ext in lfs_extensions:\n            subprocess.run(["git", "lfs", "track", ext], check=True)\n\n        # Create .gitattributes\n        with open(".gitattributes", "a") as f:\n            f.write("\\n# Dataset tracking\\n")\n\n        os.chdir(self.original_dir)\n\n    def create_version(self, version_name, commit_message):\n        """Create a new version of the dataset"""\n        os.chdir(self.dataset_dir)\n\n        # Add all files\n        subprocess.run(["git", "add", "."], check=True)\n\n        # Create commit\n        subprocess.run(["git", "commit", "-m", f"{commit_message} - {version_name}"], check=True)\n\n        # Create tag\n        subprocess.run(["git", "tag", "-a", version_name, "-m", commit_message], check=True)\n\n        os.chdir(self.original_dir)\n\n    def list_versions(self):\n        """List all available versions"""\n        os.chdir(self.dataset_dir)\n        result = subprocess.run(["git", "tag"], capture_output=True, text=True)\n        os.chdir(self.original_dir)\n\n        return result.stdout.strip().split(\'\\n\') if result.stdout.strip() else []\n'})}),"\n",(0,i.jsx)(t.h3,{id:"dvc-data-version-control",children:"DVC (Data Version Control)"}),"\n",(0,i.jsx)(t.p,{children:"For larger datasets, DVC provides better handling:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'class DVCDatasetManager:\n    def __init__(self, dataset_dir):\n        self.dataset_dir = dataset_dir\n        self.original_dir = os.getcwd()\n\n    def setup_dvc(self):\n        """Set up DVC for the dataset"""\n        os.chdir(self.dataset_dir)\n\n        # Initialize DVC\n        subprocess.run(["dvc", "init"], check=True)\n\n        # Configure remote storage (example with S3)\n        # subprocess.run(["dvc", "remote", "add", "-d", "myremote", "s3://mybucket/datasets"], check=True)\n\n        os.chdir(self.original_dir)\n\n    def add_dataset_files(self, file_patterns):\n        """Add dataset files to DVC tracking"""\n        os.chdir(self.dataset_dir)\n\n        for pattern in file_patterns:\n            subprocess.run(["dvc", "add", pattern], check=True)\n\n        # Add DVC files to git\n        subprocess.run(["git", "add", "."], check=True)\n        subprocess.run(["git", "commit", "-m", "Add dataset files with DVC"], check=True)\n\n        os.chdir(self.original_dir)\n\n    def push_to_remote(self):\n        """Push dataset to remote storage"""\n        os.chdir(self.dataset_dir)\n        subprocess.run(["dvc", "push"], check=True)\n        os.chdir(self.original_dir)\n\n    def pull_from_remote(self):\n        """Pull dataset from remote storage"""\n        os.chdir(self.dataset_dir)\n        subprocess.run(["dvc", "pull"], check=True)\n        os.chdir(self.original_dir)\n'})}),"\n",(0,i.jsx)(t.h3,{id:"custom-dataset-versioning-system",children:"Custom Dataset Versioning System"}),"\n",(0,i.jsx)(t.p,{children:"For specialized needs, a custom versioning system:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'import json\nimport hashlib\nfrom pathlib import Path\n\nclass CustomDatasetVersioner:\n    def __init__(self, dataset_dir):\n        self.dataset_dir = Path(dataset_dir)\n        self.versions_dir = self.dataset_dir / ".versions"\n        self.versions_dir.mkdir(exist_ok=True)\n\n    def create_version(self, version_name, description=""):\n        """Create a new dataset version with metadata"""\n\n        # Calculate dataset hash\n        dataset_hash = self._calculate_dataset_hash()\n\n        # Create version metadata\n        version_info = {\n            "version": version_name,\n            "description": description,\n            "created_at": datetime.now().isoformat(),\n            "dataset_hash": dataset_hash,\n            "file_count": self._count_files(),\n            "total_size": self._calculate_total_size(),\n            "metadata": self._extract_metadata()\n        }\n\n        # Save version info\n        version_file = self.versions_dir / f"{version_name}.json"\n        with open(version_file, \'w\') as f:\n            json.dump(version_info, f, indent=2)\n\n        return version_info\n\n    def _calculate_dataset_hash(self):\n        """Calculate hash of entire dataset"""\n        hasher = hashlib.sha256()\n\n        for file_path in self.dataset_dir.rglob("*"):\n            if file_path.is_file() and not str(file_path).startswith(str(self.versions_dir)):\n                with open(file_path, \'rb\') as f:\n                    while chunk := f.read(8192):\n                        hasher.update(chunk)\n\n        return hasher.hexdigest()\n\n    def _count_files(self):\n        """Count total number of files in dataset"""\n        count = 0\n        for file_path in self.dataset_dir.rglob("*"):\n            if file_path.is_file() and not str(file_path).startswith(str(self.versions_dir)):\n                count += 1\n        return count\n\n    def _calculate_total_size(self):\n        """Calculate total size of dataset"""\n        total_size = 0\n        for file_path in self.dataset_dir.rglob("*"):\n            if file_path.is_file() and not str(file_path).startswith(str(self.versions_dir)):\n                total_size += file_path.stat().st_size\n        return total_size\n\n    def _extract_metadata(self):\n        """Extract metadata from dataset"""\n        metadata = {\n            "image_formats": [],\n            "annotation_formats": [],\n            "class_distribution": {},\n            "scene_types": []\n        }\n\n        # Analyze file extensions\n        formats = {}\n        for file_path in self.dataset_dir.rglob("*"):\n            if file_path.is_file():\n                ext = file_path.suffix.lower()\n                formats[ext] = formats.get(ext, 0) + 1\n\n        metadata["file_formats"] = formats\n\n        return metadata\n\n    def list_versions(self):\n        """List all available versions"""\n        versions = []\n        for version_file in self.versions_dir.glob("*.json"):\n            with open(version_file) as f:\n                version_info = json.load(f)\n                versions.append(version_info)\n\n        # Sort by creation date\n        versions.sort(key=lambda x: x["created_at"], reverse=True)\n        return versions\n'})}),"\n",(0,i.jsx)(t.h2,{id:"dataset-quality-validation",children:"Dataset Quality Validation"}),"\n",(0,i.jsx)(t.h3,{id:"quality-metrics-and-validation",children:"Quality Metrics and Validation"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'class DatasetQualityValidator:\n    def __init__(self):\n        self.metrics = {}\n\n    def validate_dataset(self, dataset_path, expected_format="coco"):\n        """Validate the quality of a dataset"""\n\n        validation_results = {\n            "overall_score": 0.0,\n            "completeness": 0.0,\n            "consistency": 0.0,\n            "accuracy": 0.0,\n            "diversity": 0.0,\n            "issues": [],\n            "recommendations": []\n        }\n\n        if expected_format == "coco":\n            validation_results.update(self._validate_coco_dataset(dataset_path))\n        elif expected_format == "kitti":\n            validation_results.update(self._validate_kitti_dataset(dataset_path))\n        elif expected_format == "yolo":\n            validation_results.update(self._validate_yolo_dataset(dataset_path))\n\n        # Calculate overall score\n        validation_results["overall_score"] = (\n            validation_results["completeness"] * 0.3 +\n            validation_results["consistency"] * 0.3 +\n            validation_results["accuracy"] * 0.2 +\n            validation_results["diversity"] * 0.2\n        )\n\n        return validation_results\n\n    def _validate_coco_dataset(self, dataset_path):\n        """Validate COCO format dataset"""\n        import json\n\n        results = {\n            "completeness": 0.0,\n            "consistency": 0.0,\n            "accuracy": 0.0,\n            "diversity": 0.0,\n            "issues": [],\n            "recommendations": []\n        }\n\n        # Load COCO annotation file\n        annotation_files = list(Path(dataset_path).glob("annotations/*.json"))\n        if not annotation_files:\n            results["issues"].append("No annotation files found")\n            return results\n\n        with open(annotation_files[0]) as f:\n            coco_data = json.load(f)\n\n        # Validate structure\n        required_keys = ["images", "annotations", "categories"]\n        for key in required_keys:\n            if key not in coco_data:\n                results["issues"].append(f"Missing required key: {key}")\n\n        # Check completeness\n        if "images" in coco_data and "annotations" in coco_data:\n            image_count = len(coco_data["images"])\n            annotation_count = len(coco_data["annotations"])\n\n            if image_count > 0:\n                results["completeness"] = min(1.0, annotation_count / image_count)\n            else:\n                results["completeness"] = 0.0\n\n        # Check consistency\n        if "categories" in coco_data:\n            category_ids = {cat["id"] for cat in coco_data["categories"]}\n            annotation_categories = {ann["category_id"] for ann in coco_data["annotations"]}\n\n            missing_categories = annotation_categories - category_ids\n            if missing_categories:\n                results["issues"].append(f"Annotations reference non-existent categories: {missing_categories}")\n\n            results["consistency"] = 1.0 if not missing_categories else 0.8\n\n        # Check diversity\n        if "annotations" in coco_data:\n            category_distribution = {}\n            for ann in coco_data["annotations"]:\n                cat_id = ann["category_id"]\n                category_distribution[cat_id] = category_distribution.get(cat_id, 0) + 1\n\n            if category_distribution:\n                # Calculate entropy as diversity measure\n                total_annotations = sum(category_distribution.values())\n                entropy = 0\n                for count in category_distribution.values():\n                    p = count / total_annotations\n                    entropy -= p * (p and math.log2(p))\n\n                max_entropy = math.log2(len(category_distribution))\n                results["diversity"] = entropy / max_entropy if max_entropy > 0 else 0.0\n\n        return results\n\n    def _validate_image_quality(self, image_path):\n        """Validate individual image quality"""\n        from PIL import Image\n        import numpy as np\n\n        try:\n            with Image.open(image_path) as img:\n                # Check if image can be opened\n                width, height = img.size\n                mode = img.mode\n\n                quality_metrics = {\n                    "width": width,\n                    "height": height,\n                    "mode": mode,\n                    "size_bytes": os.path.getsize(image_path),\n                    "is_corrupted": False\n                }\n\n                # Check for common issues\n                if width < 10 or height < 10:\n                    quality_metrics["issues"] = ["Image too small"]\n                elif width > 10000 or height > 10000:\n                    quality_metrics["issues"] = ["Image too large"]\n                else:\n                    quality_metrics["issues"] = []\n\n                return quality_metrics\n\n        except Exception as e:\n            return {\n                "is_corrupted": True,\n                "error": str(e),\n                "issues": ["Corrupted image file"]\n            }\n\n    def generate_quality_report(self, validation_results, output_path):\n        """Generate a comprehensive quality report"""\n\n        report = {\n            "timestamp": datetime.now().isoformat(),\n            "validation_results": validation_results,\n            "summary": self._generate_summary(validation_results),\n            "detailed_analysis": self._generate_detailed_analysis(validation_results)\n        }\n\n        with open(output_path, \'w\') as f:\n            json.dump(report, f, indent=2)\n\n        return report\n\n    def _generate_summary(self, results):\n        """Generate a summary of validation results"""\n        return {\n            "overall_score": f"{results[\'overall_score\']:.2f}",\n            "status": "PASS" if results[\'overall_score\'] > 0.8 else "FAIL",\n            "main_issues": results.get(\'issues\', [])[:5],  # Top 5 issues\n            "recommendations_count": len(results.get(\'recommendations\', []))\n        }\n\n    def _generate_detailed_analysis(self, results):\n        """Generate detailed analysis"""\n        return {\n            "completeness_analysis": f"Completeness score: {results[\'completeness\']:.2f}",\n            "consistency_analysis": f"Consistency score: {results[\'consistency\']:.2f}",\n            "accuracy_analysis": f"Accuracy score: {results[\'accuracy\']:.2f}",\n            "diversity_analysis": f"Diversity score: {results[\'diversity\']:.2f}",\n            "all_issues": results.get(\'issues\', []),\n            "all_recommendations": results.get(\'recommendations\', [])\n        }\n'})}),"\n",(0,i.jsx)(t.h3,{id:"automated-quality-assurance-pipeline",children:"Automated Quality Assurance Pipeline"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'class QualityAssurancePipeline:\n    def __init__(self, dataset_path, format_type="coco"):\n        self.dataset_path = dataset_path\n        self.format_type = format_type\n        self.validator = DatasetQualityValidator()\n\n    def run_complete_qa(self):\n        """Run complete quality assurance pipeline"""\n\n        print("Starting Quality Assurance Pipeline...")\n\n        # Step 1: Basic validation\n        print("Step 1: Basic validation")\n        basic_results = self._basic_validation()\n\n        # Step 2: Format-specific validation\n        print("Step 2: Format-specific validation")\n        format_results = self._format_specific_validation()\n\n        # Step 3: Image quality validation\n        print("Step 3: Image quality validation")\n        image_results = self._image_quality_validation()\n\n        # Step 4: Annotation quality validation\n        print("Step 4: Annotation quality validation")\n        annotation_results = self._annotation_quality_validation()\n\n        # Step 5: Generate comprehensive report\n        print("Step 5: Generating report")\n        final_results = self._combine_results(\n            basic_results, format_results,\n            image_results, annotation_results\n        )\n\n        # Step 6: Create quality report\n        report = self.validator.generate_quality_report(\n            final_results,\n            f"{self.dataset_path}/quality_report.json"\n        )\n\n        print("Quality Assurance Pipeline completed!")\n        return report\n\n    def _basic_validation(self):\n        """Perform basic validation checks"""\n        results = {\n            "directory_structure": self._validate_directory_structure(),\n            "file_integrity": self._validate_file_integrity(),\n            "basic_stats": self._calculate_basic_stats()\n        }\n        return results\n\n    def _validate_directory_structure(self):\n        """Validate expected directory structure"""\n        expected_dirs = {\n            "coco": ["images", "annotations"],\n            "kitti": ["image_2", "label_2", "calib"],\n            "yolo": ["images", "labels"]\n        }\n\n        required_dirs = expected_dirs.get(self.format_type, [])\n        present_dirs = []\n        missing_dirs = []\n\n        for dir_name in required_dirs:\n            dir_path = Path(self.dataset_path) / dir_name\n            if dir_path.exists() and dir_path.is_dir():\n                present_dirs.append(dir_name)\n            else:\n                missing_dirs.append(dir_name)\n\n        return {\n            "present_dirs": present_dirs,\n            "missing_dirs": missing_dirs,\n            "structure_valid": len(missing_dirs) == 0\n        }\n\n    def _validate_file_integrity(self):\n        """Validate file integrity"""\n        import hashlib\n\n        files_to_check = list(Path(self.dataset_path).rglob("*"))\n        corrupted_files = []\n        valid_files = 0\n\n        for file_path in files_to_check:\n            if file_path.is_file():\n                try:\n                    # Try to open and read file\n                    with open(file_path, \'rb\') as f:\n                        f.read(1024)  # Read first 1KB to check if file is accessible\n                    valid_files += 1\n                except Exception:\n                    corrupted_files.append(str(file_path))\n\n        return {\n            "total_files": len(files_to_check),\n            "valid_files": valid_files,\n            "corrupted_files": corrupted_files,\n            "integrity_score": valid_files / len(files_to_check) if files_to_check else 0\n        }\n\n    def _calculate_basic_stats(self):\n        """Calculate basic dataset statistics"""\n        total_size = 0\n        file_count = 0\n        image_count = 0\n        annotation_count = 0\n\n        for file_path in Path(self.dataset_path).rglob("*"):\n            if file_path.is_file():\n                total_size += file_path.stat().st_size\n                file_count += 1\n\n                if file_path.suffix.lower() in [\'.jpg\', \'.jpeg\', \'.png\', \'.bmp\', \'.tiff\']:\n                    image_count += 1\n                elif file_path.suffix.lower() in [\'.json\', \'.txt\', \'.xml\']:\n                    annotation_count += 1\n\n        return {\n            "total_size_mb": total_size / (1024 * 1024),\n            "total_files": file_count,\n            "image_files": image_count,\n            "annotation_files": annotation_count\n        }\n'})}),"\n",(0,i.jsx)(t.h2,{id:"storage-and-organization-best-practices",children:"Storage and Organization Best Practices"}),"\n",(0,i.jsx)(t.h3,{id:"hierarchical-dataset-organization",children:"Hierarchical Dataset Organization"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'class DatasetOrganizer:\n    def __init__(self, base_path):\n        self.base_path = Path(base_path)\n\n    def create_standard_structure(self, dataset_name, task_type="detection"):\n        """Create standard dataset directory structure"""\n\n        # Create main dataset directory\n        dataset_dir = self.base_path / dataset_name\n        dataset_dir.mkdir(exist_ok=True)\n\n        # Create standard structure based on task type\n        if task_type == "detection":\n            structure = {\n                "images": ["train", "val", "test"],\n                "annotations": ["train", "val", "test"],\n                "splits": [],\n                "metadata": [],\n                "docs": []\n            }\n        elif task_type == "segmentation":\n            structure = {\n                "images": ["train", "val", "test"],\n                "masks": ["train", "val", "test"],\n                "annotations": ["train", "val", "test"],\n                "splits": [],\n                "metadata": [],\n                "docs": []\n            }\n        elif task_type == "depth_estimation":\n            structure = {\n                "rgb": ["train", "val", "test"],\n                "depth": ["train", "val", "test"],\n                "annotations": ["train", "val", "test"],\n                "splits": [],\n                "metadata": [],\n                "docs": []\n            }\n\n        # Create directory structure\n        for main_dir, sub_dirs in structure.items():\n            main_path = dataset_dir / main_dir\n            main_path.mkdir(exist_ok=True)\n\n            for sub_dir in sub_dirs:\n                sub_path = main_path / sub_dir\n                sub_path.mkdir(exist_ok=True)\n\n        # Create metadata files\n        self._create_metadata_files(dataset_dir)\n\n        return dataset_dir\n\n    def _create_metadata_files(self, dataset_dir):\n        """Create standard metadata files"""\n\n        # Create README\n        readme_path = dataset_dir / "README.md"\n        readme_content = f"""# {dataset_dir.name} Dataset\n\n## Overview\nThis dataset was generated using NVIDIA Isaac Sim for synthetic data generation.\n\n## Structure\n- `images/` - Contains RGB images\n- `annotations/` - Contains annotation files\n- `splits/` - Contains train/validation/test splits\n- `metadata/` - Contains dataset metadata\n\n## Statistics\n- Total images:\n- Total annotations:\n- Classes:\n- Generated on: {datetime.now().strftime(\'%Y-%m-%d\')}\n\n## License\nSynthetic data license - freely usable for research and commercial purposes.\n"""\n\n        with open(readme_path, \'w\') as f:\n            f.write(readme_content)\n\n        # Create dataset info\n        info_path = dataset_dir / "dataset_info.json"\n        info_data = {\n            "name": dataset_dir.name,\n            "type": "synthetic",\n            "generator": "NVIDIA Isaac Sim",\n            "created_date": datetime.now().isoformat(),\n            "version": "1.0",\n            "description": f"Synthetic dataset for {dataset_dir.name}",\n            "statistics": {},\n            "license": "Synthetic Data License"\n        }\n\n        with open(info_path, \'w\') as f:\n            json.dump(info_data, f, indent=2)\n\n    def organize_by_scene_type(self, dataset_dir, synthetic_data):\n        """Organize dataset by scene types"""\n\n        # Determine scene types from synthetic data\n        scene_types = set()\n        for sample in synthetic_data:\n            scene_type = sample.get("scene_type", "unknown")\n            scene_types.add(scene_type)\n\n        # Create scene type subdirectories\n        for scene_type in scene_types:\n            for split in ["train", "val", "test"]:\n                scene_dir = dataset_dir / "images" / split / scene_type\n                scene_dir.mkdir(parents=True, exist_ok=True)\n\n                # Move files to appropriate scene directories\n                # This would be implemented based on your specific organization needs\n'})}),"\n",(0,i.jsx)(t.h3,{id:"efficient-storage-strategies",children:"Efficient Storage Strategies"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'import zipfile\nimport tarfile\nfrom concurrent.futures import ThreadPoolExecutor\nimport multiprocessing as mp\n\nclass EfficientStorageManager:\n    def __init__(self, dataset_path):\n        self.dataset_path = Path(dataset_path)\n\n    def compress_dataset(self, output_path, compression_type="zip", max_workers=4):\n        """Compress dataset using parallel processing"""\n\n        if compression_type == "zip":\n            return self._compress_zip(output_path, max_workers)\n        elif compression_type == "tar":\n            return self._compress_tar(output_path, max_workers)\n        else:\n            raise ValueError(f"Unsupported compression type: {compression_type}")\n\n    def _compress_zip(self, output_path, max_workers):\n        """Compress dataset to ZIP format"""\n\n        def add_file_to_zip(zip_file, file_path, arc_path):\n            """Add a single file to ZIP archive"""\n            zip_file.write(file_path, arc_path, zipfile.ZIP_DEFLATED)\n\n        with zipfile.ZipFile(output_path, \'w\', zipfile.ZIP_DEFLATED, compresslevel=6) as zip_file:\n            all_files = list(self.dataset_path.rglob("*"))\n            total_files = len(all_files)\n\n            print(f"Compressing {total_files} files...")\n\n            for i, file_path in enumerate(all_files):\n                if file_path.is_file():\n                    # Calculate archive path (relative to dataset path)\n                    arc_path = file_path.relative_to(self.dataset_path)\n                    add_file_to_zip(zip_file, file_path, str(arc_path))\n\n                    if i % 1000 == 0:\n                        print(f"Progress: {i}/{total_files} files compressed")\n\n        print(f"Dataset compressed to {output_path}")\n        return output_path\n\n    def optimize_image_storage(self, quality=95, target_format="JPEG"):\n        """Optimize image storage by compressing images"""\n\n        image_extensions = {\'.jpg\', \'.jpeg\', \'.png\', \'.bmp\', \'.tiff\'}\n        optimized_count = 0\n\n        for file_path in self.dataset_path.rglob("*"):\n            if file_path.suffix.lower() in image_extensions:\n                try:\n                    with Image.open(file_path) as img:\n                        # Convert to target format if needed\n                        if target_format and img.format != target_format:\n                            # Create new filename with target extension\n                            new_path = file_path.with_suffix(f\'.{target_format.lower()}\')\n                            img.save(new_path, target_format, quality=quality, optimize=True)\n\n                            # Remove original if different\n                            if new_path != file_path:\n                                file_path.unlink()\n                        else:\n                            # Just optimize existing image\n                            img.save(file_path, optimize=True, quality=quality)\n\n                        optimized_count += 1\n\n                        if optimized_count % 100 == 0:\n                            print(f"Optimized {optimized_count} images...")\n\n                except Exception as e:\n                    print(f"Error optimizing {file_path}: {e}")\n\n        print(f"Optimized {optimized_count} images")\n        return optimized_count\n\n    def create_dataset_manifest(self):\n        """Create a manifest file for the dataset"""\n\n        manifest = {\n            "dataset_path": str(self.dataset_path),\n            "created_at": datetime.now().isoformat(),\n            "total_files": 0,\n            "total_size": 0,\n            "file_types": {},\n            "structure": {},\n            "checksums": {}\n        }\n\n        file_types = {}\n        total_size = 0\n        total_files = 0\n\n        for file_path in self.dataset_path.rglob("*"):\n            if file_path.is_file():\n                # Update file type counts\n                ext = file_path.suffix.lower()\n                file_types[ext] = file_types.get(ext, 0) + 1\n\n                # Update size\n                size = file_path.stat().st_size\n                total_size += size\n\n                # Calculate checksum\n                with open(file_path, \'rb\') as f:\n                    file_hash = hashlib.md5(f.read()).hexdigest()\n\n                manifest["checksums"][str(file_path.relative_to(self.dataset_path))] = file_hash\n                total_files += 1\n\n        manifest["total_files"] = total_files\n        manifest["total_size"] = total_size\n        manifest["file_types"] = file_types\n\n        # Save manifest\n        manifest_path = self.dataset_path / "dataset_manifest.json"\n        with open(manifest_path, \'w\') as f:\n            json.dump(manifest, f, indent=2)\n\n        print(f"Dataset manifest created: {manifest_path}")\n        return manifest_path\n'})}),"\n",(0,i.jsx)(t.h2,{id:"exercises",children:"Exercises"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Exercise 1"}),": Create a complete dataset export pipeline that converts Isaac Sim synthetic data to COCO, KITTI, and YOLO formats, including proper versioning and quality validation."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Exercise 2"}),": Implement a dataset quality validation system that checks for annotation completeness, image quality, and format compliance."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Exercise 3"}),": Design a hierarchical dataset organization system that categorizes synthetic data by scene type, object class, and environmental conditions."]}),"\n"]}),"\n",(0,i.jsxs)(t.li,{children:["\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.strong,{children:"Exercise 4"}),": Build a dataset management system with compression, manifest generation, and integrity verification capabilities."]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,i.jsx)(t.h3,{id:"dataset-management-best-practices",children:"Dataset Management Best Practices"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Standard Formats"}),": Always export to standard formats (COCO, KITTI, etc.) for compatibility"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Version Control"}),": Implement proper versioning for dataset iterations"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Quality Validation"}),": Validate datasets before making them available for training"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Metadata Documentation"}),": Include comprehensive metadata with each dataset"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Storage Optimization"}),": Optimize storage through compression and efficient formats"]}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"export-pipeline-best-practices",children:"Export Pipeline Best Practices"}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Modular Design"}),": Create modular export components for different formats"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Validation Integration"}),": Include validation in the export pipeline"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Error Handling"}),": Implement comprehensive error handling and recovery"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Progress Tracking"}),": Provide progress feedback during export operations"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.strong,{children:"Consistency Checks"}),": Verify exported data maintains consistency with source"]}),"\n"]}),"\n",(0,i.jsx)(t.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,i.jsx)(t.p,{children:"Dataset export and management represent the crucial final stage of the synthetic data generation pipeline in Isaac Sim. Proper export to standard formats ensures compatibility with machine learning frameworks, while effective versioning and quality validation systems maintain dataset integrity and usability."}),"\n",(0,i.jsx)(t.p,{children:"The combination of format conversion, version control, quality assurance, and storage optimization creates a robust pipeline that transforms synthetic data from Isaac Sim into production-ready datasets for robotics applications. These systems ensure that the high-quality synthetic data generated in Isaac Sim can be effectively utilized in real-world machine learning workflows."}),"\n",(0,i.jsx)(t.p,{children:"As we continue through this module, we'll explore how these exported datasets integrate with the broader Isaac ROS ecosystem and how they enable the development of robust perception systems for humanoid robots. The comprehensive approach to dataset management ensures that synthetic data can be effectively leveraged to accelerate robotics development and research."})]})}function _(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(c,{...e})}):c(e)}},8453:(e,t,n)=>{n.d(t,{R:()=>r,x:()=>o});var a=n(6540);const i={},s=a.createContext(i);function r(e){const t=a.useContext(s);return a.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:r(e.components),a.createElement(s.Provider,{value:t},e.children)}}}]);