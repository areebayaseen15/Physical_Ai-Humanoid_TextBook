"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[472],{6574:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>o,metadata:()=>s,toc:()=>c});const s=JSON.parse('{"id":"Module3-AI-Robot-Brain/Chapter1-Focus Advanced perception and training/3-1-3-first-isaac-project","title":"3 1.3 first isaac project","description":"Now that your development environment is set up, let\'s create your first Isaac\u2122 project. This project will demonstrate the integration of Isaac Sim for simulation and Isaac ROS for perception, creating a complete pipeline from virtual sensors to processed data.","source":"@site/docs/Module3-AI-Robot-Brain/Chapter1-Focus Advanced perception and training/3-1.3 first-isaac-project.md","sourceDirName":"Module3-AI-Robot-Brain/Chapter1-Focus Advanced perception and training","slug":"/Module3-AI-Robot-Brain/Chapter1-Focus Advanced perception and training/3-1-3-first-isaac-project","permalink":"/docs/Module3-AI-Robot-Brain/Chapter1-Focus Advanced perception and training/3-1-3-first-isaac-project","draft":false,"unlisted":false,"editUrl":"https://github.com/areebayaseen15/Ai-Humanoid-textbook/edit/main/docs/Module3-AI-Robot-Brain/Chapter1-Focus Advanced perception and training/3-1.3 first-isaac-project.md","tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"id":"3-1-3-first-isaac-project","title":"3 1.3 first isaac project","sidebar_label":"3 1.3 first isaac project","sidebar_position":0},"sidebar":"tutorialSidebar","previous":{"title":"3 1.3 development environment setup","permalink":"/docs/Module3-AI-Robot-Brain/Chapter1-Focus Advanced perception and training/3-1-3-development-environment-setup"},"next":{"title":"Chapter 2: Nav2 Path planning for bipedal humanoid movement","permalink":"/docs/category/chapter-2-nav2-path-planning-for-bipedal-humanoid-movement"}}');var r=i(4848),t=i(8453);const o={id:"3-1-3-first-isaac-project",title:"3 1.3 first isaac project",sidebar_label:"3 1.3 first isaac project",sidebar_position:0},a="3.1.4 First Isaac\u2122 Project",l={},c=[{value:"Project Overview",id:"project-overview",level:2},{value:"Creating the Simulation Environment",id:"creating-the-simulation-environment",level:2},{value:"Step 1: Launch Isaac Sim",id:"step-1-launch-isaac-sim",level:3},{value:"Step 2: Create a Simple Warehouse Environment",id:"step-2-create-a-simple-warehouse-environment",level:3},{value:"Step 3: Add a Robot Model",id:"step-3-add-a-robot-model",level:3},{value:"Setting Up the ROS Bridge",id:"setting-up-the-ros-bridge",level:2},{value:"Step 1: Configure ROS Bridge Extension",id:"step-1-configure-ros-bridge-extension",level:3},{value:"Step 2: Configure Robot Sensors for ROS",id:"step-2-configure-robot-sensors-for-ros",level:3},{value:"Creating ROS Nodes for Perception",id:"creating-ros-nodes-for-perception",level:2},{value:"Step 1: Create a ROS Workspace for Our Project",id:"step-1-create-a-ros-workspace-for-our-project",level:3},{value:"Step 2: Create a Perception Node",id:"step-2-create-a-perception-node",level:3},{value:"Step 3: Create a Navigation Node",id:"step-3-create-a-navigation-node",level:3},{value:"Step 4: Create Launch File",id:"step-4-create-launch-file",level:3},{value:"Step 5: Create Package Configuration",id:"step-5-create-package-configuration",level:3},{value:"Building and Running the Project",id:"building-and-running-the-project",level:2},{value:"Step 1: Build the Project",id:"step-1-build-the-project",level:3},{value:"Step 2: Run the Simulation and Nodes",id:"step-2-run-the-simulation-and-nodes",level:3},{value:"Debugging and Troubleshooting",id:"debugging-and-troubleshooting",level:2},{value:"Common Issues and Solutions",id:"common-issues-and-solutions",level:3},{value:"Debugging Tools",id:"debugging-tools",level:3},{value:"Extending the Project",id:"extending-the-project",level:2},{value:"Ideas for Enhancement",id:"ideas-for-enhancement",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Simulation Best Practices",id:"simulation-best-practices",level:3},{value:"ROS Development Best Practices",id:"ros-development-best-practices",level:3},{value:"Conclusion",id:"conclusion",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"314-first-isaac-project",children:"3.1.4 First Isaac\u2122 Project"})}),"\n",(0,r.jsx)(n.p,{children:"Now that your development environment is set up, let's create your first Isaac\u2122 project. This project will demonstrate the integration of Isaac Sim for simulation and Isaac ROS for perception, creating a complete pipeline from virtual sensors to processed data."}),"\n",(0,r.jsx)(n.h2,{id:"project-overview",children:"Project Overview"}),"\n",(0,r.jsx)(n.p,{children:"Our first project will create a simple warehouse environment where a robot navigates through aisles, detects objects, and localizes itself. This project will include:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:"A basic warehouse scene in Isaac Sim"}),"\n",(0,r.jsx)(n.li,{children:"A simple wheeled robot model"}),"\n",(0,r.jsx)(n.li,{children:"Camera and LiDAR sensors on the robot"}),"\n",(0,r.jsx)(n.li,{children:"Isaac ROS perception nodes for object detection"}),"\n",(0,r.jsx)(n.li,{children:"Basic navigation capabilities"}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"creating-the-simulation-environment",children:"Creating the Simulation Environment"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-launch-isaac-sim",children:"Step 1: Launch Isaac Sim"}),"\n",(0,r.jsx)(n.p,{children:"Start Isaac Sim and create a new stage:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"isaac-sim\n"})}),"\n",(0,r.jsx)(n.p,{children:"Once Isaac Sim launches:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:'Click "New Stage" to create an empty scene'}),"\n",(0,r.jsx)(n.li,{children:'Save the stage as "warehouse_scene.usd" in your project directory'}),"\n",(0,r.jsx)(n.li,{children:"Set up the basic environment"}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-2-create-a-simple-warehouse-environment",children:"Step 2: Create a Simple Warehouse Environment"}),"\n",(0,r.jsx)(n.p,{children:"In Isaac Sim, we'll create a basic warehouse environment using the Stage and Prim tools:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Create the Floor"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Right-click in the viewport \u2192 Create \u2192 Cube"}),"\n",(0,r.jsx)(n.li,{children:"Scale it to 10x10x0.1 units to create a floor"}),"\n",(0,r.jsx)(n.li,{children:"Position at (0, 0, 0)"}),"\n",(0,r.jsx)(n.li,{children:"Apply a concrete material from the Material Library"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add Warehouse Shelves"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Create several rectangular prisms for shelves"}),"\n",(0,r.jsx)(n.li,{children:"Position them to create aisles (e.g., 2m apart)"}),"\n",(0,r.jsx)(n.li,{children:"Add simple box shapes as inventory items"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Set Up Lighting"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add an Environment Light (Window \u2192 Create \u2192 Environment Light)"}),"\n",(0,r.jsx)(n.li,{children:"Adjust intensity to 3000 for realistic warehouse lighting"}),"\n",(0,r.jsx)(n.li,{children:"Add a Distant Light for shadows"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Create a Sky Dome"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add a Sky Dome prim for realistic sky environment"}),"\n",(0,r.jsx)(n.li,{children:"Configure with realistic sky parameters"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-3-add-a-robot-model",children:"Step 3: Add a Robot Model"}),"\n",(0,r.jsx)(n.p,{children:"For our first project, we'll use a simple differential drive robot:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Import Robot Model"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Download a simple robot model (e.g., TurtleBot3 or create a custom one)"}),"\n",(0,r.jsx)(n.li,{children:"Import via Window \u2192 Import \u2192 Import USD"}),"\n",(0,r.jsx)(n.li,{children:"Position the robot at the starting location in the warehouse"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Configure Robot Prims"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Set up the robot hierarchy with proper joint articulation"}),"\n",(0,r.jsx)(n.li,{children:"Add wheel joints for differential drive"}),"\n",(0,r.jsx)(n.li,{children:"Configure physics properties for realistic movement"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Add Sensors to Robot"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add a camera sensor to the robot's front"}),"\n",(0,r.jsx)(n.li,{children:"Add a simple LiDAR sensor"}),"\n",(0,r.jsx)(n.li,{children:"Configure sensor parameters appropriately"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"setting-up-the-ros-bridge",children:"Setting Up the ROS Bridge"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-configure-ros-bridge-extension",children:"Step 1: Configure ROS Bridge Extension"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Enable the ROS Bridge extension:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Go to Window \u2192 Extensions"}),"\n",(0,r.jsx)(n.li,{children:'Search for "ROS" and enable "ROS2 Bridge"'}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsx)(n.p,{children:"Add ROS Bridge to your stage:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:'In the Create menu, search for "ROS Bridge"'}),"\n",(0,r.jsx)(n.li,{children:"Add the bridge to your stage"}),"\n",(0,r.jsx)(n.li,{children:"Configure the bridge settings (domain ID, etc.)"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"step-2-configure-robot-sensors-for-ros",children:"Step 2: Configure Robot Sensors for ROS"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Camera Configuration"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Select the camera prim on your robot"}),"\n",(0,r.jsx)(n.li,{children:'Add the "Isaac ROS Bridge" component'}),"\n",(0,r.jsxs)(n.li,{children:["Configure to publish to ",(0,r.jsx)(n.code,{children:"/camera/image_raw"})," topic"]}),"\n",(0,r.jsx)(n.li,{children:"Set appropriate image format and resolution"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"LiDAR Configuration"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Select the LiDAR prim on your robot"}),"\n",(0,r.jsx)(n.li,{children:'Add the "Isaac ROS Bridge" component'}),"\n",(0,r.jsxs)(n.li,{children:["Configure to publish to ",(0,r.jsx)(n.code,{children:"/scan"})," topic"]}),"\n",(0,r.jsx)(n.li,{children:"Set appropriate range and resolution parameters"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robot State Publisher"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add a Robot State Publisher component"}),"\n",(0,r.jsx)(n.li,{children:"Configure to publish joint states and TF transforms"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"creating-ros-nodes-for-perception",children:"Creating ROS Nodes for Perception"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-create-a-ros-workspace-for-our-project",children:"Step 1: Create a ROS Workspace for Our Project"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Create project directory\nmkdir -p ~/isaac_projects/first_project/src\ncd ~/isaac_projects/first_project\n\n# Source ROS and Isaac ROS\nsource /opt/ros/humble/setup.bash\nsource ~/isaac_ros_ws/install/setup.bash\n\n# Initialize workspace\ncolcon build\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-2-create-a-perception-node",children:"Step 2: Create a Perception Node"}),"\n",(0,r.jsx)(n.p,{children:"Create a simple perception node that processes camera data:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# ~/isaac_projects/first_project/src/first_isaac_project/first_isaac_project/perception_node.py\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom vision_msgs.msg import Detection2DArray\nfrom cv_bridge import CvBridge\nimport cv2\nimport numpy as np\n\nclass PerceptionNode(Node):\n    def __init__(self):\n        super().__init__('perception_node')\n\n        # Create subscriber for camera images\n        self.image_subscription = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.image_callback,\n            10)\n\n        # Create publisher for detections\n        self.detection_publisher = self.create_publisher(\n            Detection2DArray,\n            '/camera/detections',\n            10)\n\n        # Initialize OpenCV bridge\n        self.bridge = CvBridge()\n\n        self.get_logger().info('Perception Node Initialized')\n\n    def image_callback(self, msg):\n        # Convert ROS Image to OpenCV\n        cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='bgr8')\n\n        # Simple object detection using color thresholding\n        hsv = cv2.cvtColor(cv_image, cv2.COLOR_BGR2HSV)\n\n        # Define range for red objects (example)\n        lower_red = np.array([0, 50, 50])\n        upper_red = np.array([10, 255, 255])\n        mask1 = cv2.inRange(hsv, lower_red, upper_red)\n\n        lower_red = np.array([170, 50, 50])\n        upper_red = np.array([180, 255, 255])\n        mask2 = cv2.inRange(hsv, lower_red, upper_red)\n\n        mask = mask1 + mask2\n\n        # Find contours\n        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n\n        # Create detection message\n        detection_array = Detection2DArray()\n        detection_array.header = msg.header\n\n        for contour in contours:\n            if cv2.contourArea(contour) > 100:  # Filter small contours\n                x, y, w, h = cv2.boundingRect(contour)\n\n                detection = Detection2D()\n                detection.header = msg.header\n                detection.bbox.center.x = x + w/2\n                detection.bbox.center.y = y + h/2\n                detection.bbox.size_x = w\n                detection.bbox.size_y = h\n\n                detection_array.detections.append(detection)\n\n        # Publish detections\n        self.detection_publisher.publish(detection_array)\n\n        # Optionally publish processed image\n        processed_msg = self.bridge.cv2_to_imgmsg(cv_image, encoding='bgr8')\n        # In a real implementation, you'd publish to a processed image topic\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    perception_node = PerceptionNode()\n\n    try:\n        rclpy.spin(perception_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        perception_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-3-create-a-navigation-node",children:"Step 3: Create a Navigation Node"}),"\n",(0,r.jsx)(n.p,{children:"Create a simple navigation node that moves the robot:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# ~/isaac_projects/first_project/src/first_isaac_project/first_isaac_project/navigation_node.py\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import Twist\nfrom sensor_msgs.msg import LaserScan\nimport math\n\nclass NavigationNode(Node):\n    def __init__(self):\n        super().__init__('navigation_node')\n\n        # Create publisher for velocity commands\n        self.cmd_vel_publisher = self.create_publisher(\n            Twist,\n            '/cmd_vel',\n            10)\n\n        # Create subscriber for LiDAR data\n        self.scan_subscription = self.create_subscription(\n            LaserScan,\n            '/scan',\n            self.scan_callback,\n            10)\n\n        # Timer for control loop\n        self.timer = self.create_timer(0.1, self.control_loop)\n\n        # Robot state\n        self.obstacle_detected = False\n        self.obstacle_distance = float('inf')\n\n        self.get_logger().info('Navigation Node Initialized')\n\n    def scan_callback(self, msg):\n        # Check for obstacles in front of robot (\xb130 degrees)\n        min_index = int(len(msg.ranges) * 0.45)  # Front-left\n        max_index = int(len(msg.ranges) * 0.55)  # Front-right\n\n        front_ranges = msg.ranges[min_index:max_index]\n        valid_ranges = [r for r in front_ranges if r > msg.range_min and r < msg.range_max]\n\n        if valid_ranges:\n            self.obstacle_distance = min(valid_ranges)\n            self.obstacle_detected = self.obstacle_distance < 1.0  # 1 meter threshold\n        else:\n            self.obstacle_detected = False\n            self.obstacle_distance = float('inf')\n\n    def control_loop(self):\n        twist = Twist()\n\n        if self.obstacle_detected:\n            # Stop and turn right\n            twist.linear.x = 0.0\n            twist.angular.z = -0.5  # Turn right\n        else:\n            # Move forward\n            twist.linear.x = 0.5\n            twist.angular.z = 0.0\n\n        self.cmd_vel_publisher.publish(twist)\n\ndef main(args=None):\n    rclpy.init(args=args)\n\n    navigation_node = NavigationNode()\n\n    try:\n        rclpy.spin(navigation_node)\n    except KeyboardInterrupt:\n        pass\n    finally:\n        navigation_node.destroy_node()\n        rclpy.shutdown()\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-4-create-launch-file",children:"Step 4: Create Launch File"}),"\n",(0,r.jsx)(n.p,{children:"Create a launch file to start all nodes together:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# ~/isaac_projects/first_project/src/first_isaac_project/first_isaac_project/launch/first_project_launch.py\nfrom launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom ament_index_python.packages import get_package_share_directory\nimport os\n\ndef generate_launch_description():\n    perception_node = Node(\n        package='first_isaac_project',\n        executable='perception_node',\n        name='perception_node',\n        output='screen'\n    )\n\n    navigation_node = Node(\n        package='first_isaac_project',\n        executable='navigation_node',\n        name='navigation_node',\n        output='screen'\n    )\n\n    return LaunchDescription([\n        perception_node,\n        navigation_node\n    ])\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-5-create-package-configuration",children:"Step 5: Create Package Configuration"}),"\n",(0,r.jsx)(n.p,{children:"Create the package.xml file:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<?xml-model href="http://download.ros.org/schema/package_format3.xsd" schematypens="http://www.w3.org/2001/XMLSchema"?>\n<package format="3">\n  <name>first_isaac_project</name>\n  <version>0.0.1</version>\n  <description>First Isaac Project for Module 3</description>\n  <maintainer email="user@example.com">User</maintainer>\n  <license>Apache-2.0</license>\n\n  <depend>rclpy</depend>\n  <depend>std_msgs</depend>\n  <depend>sensor_msgs</depend>\n  <depend>geometry_msgs</depend>\n  <depend>vision_msgs</depend>\n  <depend>cv_bridge</depend>\n\n  <exec_depend>launch</exec_depend>\n  <exec_depend>launch_ros</exec_depend>\n\n  <test_depend>ament_copyright</test_depend>\n  <test_depend>ament_flake8</test_depend>\n  <test_depend>ament_pep257</test_depend>\n  <test_depend>python3-pytest</test_depend>\n\n  <export>\n    <build_type>ament_python</build_type>\n  </export>\n</package>\n'})}),"\n",(0,r.jsx)(n.p,{children:"And the setup.py file:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"from setuptools import setup\nfrom glob import glob\nimport os\n\npackage_name = 'first_isaac_project'\n\nsetup(\n    name=package_name,\n    version='0.0.1',\n    packages=[package_name],\n    data_files=[\n        ('share/ament_index/resource_index/packages',\n            ['resource/' + package_name]),\n        ('share/' + package_name, ['package.xml']),\n        (os.path.join('share', package_name, 'launch'), glob('launch/*.py')),\n    ],\n    install_requires=['setuptools'],\n    zip_safe=True,\n    maintainer='User',\n    maintainer_email='user@example.com',\n    description='First Isaac Project for Module 3',\n    license='Apache-2.0',\n    tests_require=['pytest'],\n    entry_points={\n        'console_scripts': [\n            'perception_node = first_isaac_project.perception_node:main',\n            'navigation_node = first_isaac_project.navigation_node:main',\n        ],\n    },\n)\n"})}),"\n",(0,r.jsx)(n.h2,{id:"building-and-running-the-project",children:"Building and Running the Project"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-build-the-project",children:"Step 1: Build the Project"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"cd ~/isaac_projects/first_project\nsource /opt/ros/humble/setup.bash\nsource ~/isaac_ros_ws/install/setup.bash\ncolcon build --packages-select first_isaac_project\nsource install/setup.bash\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-2-run-the-simulation-and-nodes",children:"Step 2: Run the Simulation and Nodes"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Start Isaac Sim"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Launch Isaac Sim with your warehouse scene"}),"\n",(0,r.jsx)(n.li,{children:"Ensure the ROS Bridge is configured and running"}),"\n",(0,r.jsx)(n.li,{children:"Make sure the robot is positioned correctly"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Run ROS Nodes"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"ros2 launch first_isaac_project first_project_launch.py\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Monitor Topics"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check available topics\nros2 topic list\n\n# Monitor camera data\nros2 topic echo /camera/image_raw --field data | head -n 10\n\n# Monitor LiDAR data\nros2 topic echo /scan --field ranges | head -n 5\n"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"debugging-and-troubleshooting",children:"Debugging and Troubleshooting"}),"\n",(0,r.jsx)(n.h3,{id:"common-issues-and-solutions",children:"Common Issues and Solutions"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ROS Bridge Connection Issues"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Verify that Isaac Sim ROS Bridge extension is enabled"}),"\n",(0,r.jsx)(n.li,{children:"Check that domain IDs match between Isaac Sim and ROS nodes"}),"\n",(0,r.jsx)(n.li,{children:"Ensure network settings allow communication"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Sensor Data Not Publishing"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Check that sensor prims have ROS bridge components attached"}),"\n",(0,r.jsx)(n.li,{children:"Verify topic names match between simulation and ROS nodes"}),"\n",(0,r.jsx)(n.li,{children:"Ensure Isaac Sim is actively simulating (play button)"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Robot Not Moving"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Check that ",(0,r.jsx)(n.code,{children:"/cmd_vel"})," topic is being published to"]}),"\n",(0,r.jsx)(n.li,{children:"Verify that the robot in Isaac Sim has differential drive configured"}),"\n",(0,r.jsx)(n.li,{children:"Check that ROS bridge is properly configured for actuator control"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Perception Node Not Processing Images"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Verify image topic name matches what's published by Isaac Sim"}),"\n",(0,r.jsx)(n.li,{children:"Check that OpenCV and cv_bridge are properly installed"}),"\n",(0,r.jsx)(n.li,{children:"Ensure image encoding formats match"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"debugging-tools",children:"Debugging Tools"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"ROS 2 Tools"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Check node graph\nrqt_graph\n\n# Monitor topics\nrqt_plot\n\n# Visualize robot state\nrviz2\n"})}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Isaac Sim Debugging"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Use Isaac Sim's built-in debugging tools"}),"\n",(0,r.jsx)(n.li,{children:"Check the log window for errors"}),"\n",(0,r.jsx)(n.li,{children:"Use the Inspector to verify prim properties"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Python Debugging"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add logging statements to your nodes"}),"\n",(0,r.jsxs)(n.li,{children:["Use ROS 2 logging: ",(0,r.jsx)(n.code,{children:"self.get_logger().info('message')"})]}),"\n",(0,r.jsxs)(n.li,{children:["Check ROS 2 log files in ",(0,r.jsx)(n.code,{children:"~/.ros/log/"})]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"extending-the-project",children:"Extending the Project"}),"\n",(0,r.jsx)(n.h3,{id:"ideas-for-enhancement",children:"Ideas for Enhancement"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Advanced Perception"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Replace simple color thresholding with a trained neural network"}),"\n",(0,r.jsx)(n.li,{children:"Add 3D object detection using depth data"}),"\n",(0,r.jsx)(n.li,{children:"Implement SLAM for mapping and localization"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Improved Navigation"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Integrate with ROS 2 Navigation (Nav2) stack"}),"\n",(0,r.jsx)(n.li,{children:"Add path planning capabilities"}),"\n",(0,r.jsx)(n.li,{children:"Implement obstacle avoidance algorithms"}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Simulation Enhancement"}),":"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Add more realistic warehouse objects"}),"\n",(0,r.jsx)(n.li,{children:"Include dynamic obstacles (moving objects)"}),"\n",(0,r.jsx)(n.li,{children:"Add lighting variations for more realistic perception"}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"exercises",children:"Exercises"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Exercise 1"}),": Modify the perception node to detect different colored objects by adjusting the HSV color ranges."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Exercise 2"}),": Add a new sensor to your robot (e.g., IMU) and create a node to process its data."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Exercise 3"}),": Create a more sophisticated navigation strategy that can follow a predetermined path through the warehouse."]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Exercise 4"}),": Implement a simple mapping system that records the robot's path and detected objects."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,r.jsx)(n.h3,{id:"simulation-best-practices",children:"Simulation Best Practices"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Realistic Physics"}),": Configure physics properties to match real-world values"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Sensor Accuracy"}),": Set sensor parameters to realistic values based on actual hardware"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Performance"}),": Balance simulation quality with real-time performance requirements"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Validation"}),": Regularly validate simulation results against real-world data"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"ros-development-best-practices",children:"ROS Development Best Practices"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Modularity"}),": Keep nodes focused on single responsibilities"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Error Handling"}),": Implement proper error handling and graceful degradation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Logging"}),": Use appropriate logging levels for debugging and monitoring"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Configuration"}),": Use ROS parameters for configurable values"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,r.jsx)(n.p,{children:"This first Isaac\u2122 project demonstrates the integration of Isaac Sim for realistic simulation and Isaac ROS for hardware-accelerated perception. You've created a complete pipeline that includes:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"A photorealistic warehouse simulation environment"}),"\n",(0,r.jsx)(n.li,{children:"A robot with camera and LiDAR sensors"}),"\n",(0,r.jsx)(n.li,{children:"ROS nodes for perception and navigation"}),"\n",(0,r.jsx)(n.li,{children:"Proper configuration of the ROS bridge"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"This foundation provides the basis for more complex robotics applications using the NVIDIA Isaac\u2122 platform. In the following chapters, we'll explore more advanced topics including Isaac ROS packages, visual SLAM, and Nav2 integration for humanoid robots."}),"\n",(0,r.jsx)(n.p,{children:"The project also serves as a template that you can extend with more sophisticated perception algorithms, navigation strategies, and simulation scenarios. The modular design allows you to experiment with different components independently while maintaining the overall system architecture."})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>a});var s=i(6540);const r={},t=s.createContext(r);function o(e){const n=s.useContext(t);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);