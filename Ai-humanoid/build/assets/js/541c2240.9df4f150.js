"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook=globalThis.webpackChunkphysical_ai_humanoid_robotics_textbook||[]).push([[6564],{3207:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>d,contentTitle:()=>s,default:()=>m,frontMatter:()=>o,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/domain-randomization","title":"domain randomization","description":"Domain randomization is a powerful technique in synthetic data generation that systematically varies simulation parameters to improve the sim-to-real transfer of machine learning models. By training models on data with wide variations in visual and physical properties, domain randomization helps create models that are robust to the differences between synthetic and real-world data.","source":"@site/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/domain-randomization.md","sourceDirName":"Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation","slug":"/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/domain-randomization","permalink":"/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/domain-randomization","draft":false,"unlisted":false,"editUrl":"https://github.com/areebayaseen15/Ai-Humanoid-textbook/edit/main/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/domain-randomization.md","tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"id":"domain-randomization","title":"domain randomization","sidebar_label":"domain randomization","sidebar_position":0},"sidebar":"tutorialSidebar","previous":{"title":"dataset export and management","permalink":"/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/dataset-export-and-management"},"next":{"title":"ground truth and annotations","permalink":"/docs/Module3-AI-Robot-Brain/Chapter4-saac ROS Hardware-accelerated VSLAM (Visual SLAM) and navigation/ground-truth-and-annotations"}}');var a=i(4848),r=i(8453);const o={id:"domain-randomization",title:"domain randomization",sidebar_label:"domain randomization",sidebar_position:0},s="3.3.3 Domain Randomization",d={},l=[{value:"Understanding Domain Randomization",id:"understanding-domain-randomization",level:2},{value:"The Core Concept",id:"the-core-concept",level:3},{value:"Theoretical Foundation",id:"theoretical-foundation",level:3},{value:"Parameter Space Exploration",id:"parameter-space-exploration",level:3},{value:"Texture and Material Randomization",id:"texture-and-material-randomization",level:2},{value:"Albedo Randomization",id:"albedo-randomization",level:3},{value:"Roughness and Metallic Randomization",id:"roughness-and-metallic-randomization",level:3},{value:"Procedural Texture Generation",id:"procedural-texture-generation",level:3},{value:"Lighting Condition Variations",id:"lighting-condition-variations",level:2},{value:"Directional Light Randomization",id:"directional-light-randomization",level:3},{value:"Environmental Lighting",id:"environmental-lighting",level:3},{value:"Object Pose Randomization",id:"object-pose-randomization",level:2},{value:"Position and Orientation Randomization",id:"position-and-orientation-randomization",level:3},{value:"Object Distribution Patterns",id:"object-distribution-patterns",level:3},{value:"Camera Parameter Variations",id:"camera-parameter-variations",level:2},{value:"Intrinsic Parameter Randomization",id:"intrinsic-parameter-randomization",level:3},{value:"Extrinsic Parameter Randomization",id:"extrinsic-parameter-randomization",level:3},{value:"Statistical Distribution Strategies",id:"statistical-distribution-strategies",level:2},{value:"Uniform vs Non-Uniform Distributions",id:"uniform-vs-non-uniform-distributions",level:3},{value:"Correlated Parameter Randomization",id:"correlated-parameter-randomization",level:3},{value:"Implementation Best Practices",id:"implementation-best-practices",level:2},{value:"Progressive Domain Randomization",id:"progressive-domain-randomization",level:3},{value:"Validation and Monitoring",id:"validation-and-monitoring",level:3},{value:"Exercises",id:"exercises",level:2},{value:"Best Practices",id:"best-practices",level:2},{value:"Domain Randomization Best Practices",id:"domain-randomization-best-practices",level:3},{value:"Parameter Selection Best Practices",id:"parameter-selection-best-practices",level:3},{value:"Conclusion",id:"conclusion",level:2}];function c(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...n.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(e.header,{children:(0,a.jsx)(e.h1,{id:"333-domain-randomization",children:"3.3.3 Domain Randomization"})}),"\n",(0,a.jsx)(e.p,{children:"Domain randomization is a powerful technique in synthetic data generation that systematically varies simulation parameters to improve the sim-to-real transfer of machine learning models. By training models on data with wide variations in visual and physical properties, domain randomization helps create models that are robust to the differences between synthetic and real-world data."}),"\n",(0,a.jsx)(e.h2,{id:"understanding-domain-randomization",children:"Understanding Domain Randomization"}),"\n",(0,a.jsx)(e.h3,{id:"the-core-concept",children:"The Core Concept"}),"\n",(0,a.jsx)(e.p,{children:'Domain randomization addresses the fundamental challenge in synthetic data generation: the gap between synthetic and real-world data. This gap, known as the "domain gap," occurs because synthetic environments cannot perfectly replicate all aspects of real-world physics, lighting, materials, and sensor characteristics.'}),"\n",(0,a.jsx)(e.p,{children:"The domain randomization approach acknowledges that attempting to perfectly match real-world conditions in simulation is often impossible or impractical. Instead, it embraces the differences by systematically varying simulation parameters across wide ranges, forcing the model to learn features that are invariant to these variations."}),"\n",(0,a.jsx)(e.h3,{id:"theoretical-foundation",children:"Theoretical Foundation"}),"\n",(0,a.jsx)(e.p,{children:"Domain randomization is based on the principle that if a model can perform well across a wide range of conditions in simulation, it will be more likely to perform well in real-world conditions it hasn't seen before. This is formalized in domain adaptation theory, where the goal is to learn representations that generalize across domains."}),"\n",(0,a.jsx)(e.p,{children:"The technique is particularly effective because it:"}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Forces models to focus on relevant features rather than spurious correlations"}),"\n",(0,a.jsx)(e.li,{children:"Increases model robustness to environmental variations"}),"\n",(0,a.jsx)(e.li,{children:"Reduces overfitting to specific simulation conditions"}),"\n",(0,a.jsx)(e.li,{children:"Enables zero-shot transfer to real-world data"}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"parameter-space-exploration",children:"Parameter Space Exploration"}),"\n",(0,a.jsx)(e.p,{children:"Domain randomization involves systematically varying parameters across multiple dimensions:"}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Visual Parameters"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Lighting conditions (intensity, color, direction)"}),"\n",(0,a.jsx)(e.li,{children:"Material properties (albedo, roughness, metallic)"}),"\n",(0,a.jsx)(e.li,{children:"Camera properties (noise, distortion, exposure)"}),"\n",(0,a.jsx)(e.li,{children:"Environmental effects (fog, rain, snow)"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Physical Parameters"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Friction coefficients"}),"\n",(0,a.jsx)(e.li,{children:"Mass distributions"}),"\n",(0,a.jsx)(e.li,{children:"Joint dynamics"}),"\n",(0,a.jsx)(e.li,{children:"Collision properties"}),"\n"]}),"\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Scene Parameters"}),":"]}),"\n",(0,a.jsxs)(e.ul,{children:["\n",(0,a.jsx)(e.li,{children:"Object positions and orientations"}),"\n",(0,a.jsx)(e.li,{children:"Object counts and types"}),"\n",(0,a.jsx)(e.li,{children:"Background complexity"}),"\n",(0,a.jsx)(e.li,{children:"Scene layout variations"}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"texture-and-material-randomization",children:"Texture and Material Randomization"}),"\n",(0,a.jsx)(e.h3,{id:"albedo-randomization",children:"Albedo Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Albedo refers to the base color of a material without lighting effects. Randomizing albedo helps models focus on shape and geometric features rather than specific colors."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"# Example: Albedo randomization using Isaac Sim Replicator\nimport omni.replicator.core as rep\n\ndef randomize_albedo():\n    \"\"\"Randomize material albedo across the scene\"\"\"\n\n    with rep.randomizer:\n        # Get all prims with materials\n        prims = rep.get.prim_with_property(\n            prim_types=['Mesh'],\n            property_name='material'\n        )\n\n        with prims:\n            # Randomize albedo using various distributions\n            albedo_values = [\n                (0.8, 0.1, 0.1),  # Red\n                (0.1, 0.8, 0.1),  # Green\n                (0.1, 0.1, 0.8),  # Blue\n                (0.8, 0.8, 0.1),  # Yellow\n                (0.8, 0.1, 0.8),  # Magenta\n                (0.1, 0.8, 0.8),  # Cyan\n                (0.8, 0.8, 0.8),  # Gray\n                (0.2, 0.2, 0.2),  # Dark gray\n            ]\n\n            # Apply random albedo values\n            rep.randomizer.material_albedo(\n                rep.distribution.choice(albedo_values)\n            )\n\n            # Or use continuous randomization\n            rep.randomizer.material_albedo(\n                rep.distribution.uniform((0.1, 0.1, 0.1), (1.0, 1.0, 1.0))\n            )\n\ndef advanced_albedo_randomization():\n    \"\"\"Advanced albedo randomization with realistic constraints\"\"\"\n\n    with rep.randomizer:\n        prims = rep.get.prim_with_property(\n            prim_types=['Mesh'],\n            property_name='material'\n        )\n\n        with prims:\n            # Create more sophisticated albedo variations\n            # Group by object type for more realistic randomization\n\n            # For vehicles, keep colors somewhat realistic\n            vehicle_prims = rep.get.prim_with_property(\n                prim_paths=['/World/Vehicles/*']\n            )\n\n            with vehicle_prims:\n                vehicle_colors = [\n                    (0.8, 0.1, 0.1),    # Red\n                    (0.1, 0.1, 0.8),    # Blue\n                    (0.8, 0.8, 0.8),    # Silver\n                    (0.2, 0.2, 0.2),    # Black\n                    (1.0, 1.0, 1.0),    # White\n                    (0.6, 0.4, 0.1),    # Brown\n                ]\n                rep.randomizer.material_albedo(\n                    rep.distribution.choice(vehicle_colors)\n                )\n\n            # For buildings, use more architectural colors\n            building_prims = rep.get.prim_with_property(\n                prim_paths=['/World/Buildings/*']\n            )\n\n            with building_prims:\n                building_colors = [\n                    (0.7, 0.7, 0.7),    # Concrete gray\n                    (0.5, 0.5, 0.5),    # Dark gray\n                    (0.8, 0.7, 0.6),    # Beige\n                    (0.6, 0.6, 0.7),    # Light blue gray\n                    (0.5, 0.4, 0.4),    # Brown gray\n                ]\n                rep.randomizer.material_albedo(\n                    rep.distribution.choice(building_colors)\n                )\n"})}),"\n",(0,a.jsx)(e.h3,{id:"roughness-and-metallic-randomization",children:"Roughness and Metallic Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Roughness and metallic properties affect how light interacts with surfaces, creating different visual appearances."}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def randomize_surface_properties():\n    \"\"\"Randomize roughness and metallic properties\"\"\"\n\n    with rep.randomizer:\n        prims = rep.get.prim_with_property(\n            prim_types=['Mesh'],\n            property_name='material'\n        )\n\n        with prims:\n            # Randomize roughness (0.0 = smooth, 1.0 = rough)\n            rep.randomizer.material_roughness(\n                rep.distribution.uniform(0.1, 0.9)\n            )\n\n            # Randomize metallic properties (0.0 = non-metal, 1.0 = metal)\n            rep.randomizer.material_metallic(\n                rep.distribution.uniform(0.0, 0.3)  # Keep mostly non-metallic\n            )\n\ndef material_category_randomization():\n    \"\"\"Apply different material properties based on object categories\"\"\"\n\n    # Different categories have different material property ranges\n    material_configs = {\n        'metal': {\n            'roughness_range': (0.0, 0.5),\n            'metallic_range': (0.8, 1.0),\n            'albedo_range': (0.5, 1.0)\n        },\n        'plastic': {\n            'roughness_range': (0.2, 0.8),\n            'metallic_range': (0.0, 0.1),\n            'albedo_range': (0.1, 1.0)\n        },\n        'fabric': {\n            'roughness_range': (0.6, 0.9),\n            'metallic_range': (0.0, 0.05),\n            'albedo_range': (0.1, 0.9)\n        },\n        'wood': {\n            'roughness_range': (0.3, 0.8),\n            'metallic_range': (0.0, 0.05),\n            'albedo_range': (0.3, 0.8)\n        }\n    }\n\n    for category, config in material_configs.items():\n        with rep.randomizer:\n            prims = rep.get.prim_with_property(\n                prim_paths=[f'/World/{category.title()}s/*']\n            )\n\n            with prims:\n                rep.randomizer.material_roughness(\n                    rep.distribution.uniform(\n                        config['roughness_range'][0],\n                        config['roughness_range'][1]\n                    )\n                )\n                rep.randomizer.material_metallic(\n                    rep.distribution.uniform(\n                        config['metallic_range'][0],\n                        config['metallic_range'][1]\n                    )\n                )\n"})}),"\n",(0,a.jsx)(e.h3,{id:"procedural-texture-generation",children:"Procedural Texture Generation"}),"\n",(0,a.jsx)(e.p,{children:"Creating procedural textures that vary systematically:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def create_procedural_textures():\n    \"\"\"Create procedural textures with random parameters\"\"\"\n\n    # Example using procedural noise patterns\n    def procedural_texture_randomizer():\n        with rep.randomizer:\n            prims = rep.get.prim_with_property(\n                prim_types=['Mesh'],\n                property_name='material'\n            )\n\n            with prims:\n                # Apply procedural noise patterns\n                noise_types = ['perlin', 'voronoi', 'simplex']\n\n                for noise_type in noise_types:\n                    # Create different noise patterns\n                    # This would use Isaac Sim's material graph system\n                    pass\n\n    return procedural_texture_randomizer\n"})}),"\n",(0,a.jsx)(e.h2,{id:"lighting-condition-variations",children:"Lighting Condition Variations"}),"\n",(0,a.jsx)(e.h3,{id:"directional-light-randomization",children:"Directional Light Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Randomizing the primary light source (sun/sky) in the scene:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def randomize_directional_light():\n    \"\"\"Randomize directional light properties\"\"\"\n\n    with rep.randomizer:\n        lights = rep.get.light(\n            prim_paths=['/World/Light/*'],\n            light_types=['DistantLight']\n        )\n\n        with lights:\n            # Randomize light direction (solar position)\n            # Using spherical coordinates\n            elevation = rep.distribution.uniform(10, 80)  # degrees from horizon\n            azimuth = rep.distribution.uniform(0, 360)    # compass direction\n\n            # Convert to cartesian coordinates\n            import math\n            elevation_rad = rep.distribution.uniform(\n                math.radians(10), math.radians(80)\n            )\n            azimuth_rad = rep.distribution.uniform(\n                0, 2 * math.pi\n            )\n\n            # Calculate direction vector\n            direction_x = rep.distribution.uniform(-1, 1)\n            direction_y = rep.distribution.uniform(0.1, 1)\n            direction_z = rep.distribution.uniform(-1, 1)\n\n            rep.modify.pose(\n                position=rep.distribution.uniform(\n                    (-1000, 1000, -1000), (1000, 1000, 1000)\n                )\n            )\n\n            # Randomize light intensity\n            rep.light.intensity(rep.distribution.uniform(500, 2000))\n\n            # Randomize light color temperature\n            color_temp = rep.distribution.uniform(3000, 8000)  # Kelvin\n            # Convert to RGB approximation\n            rep.light.color(rep.distribution.uniform(\n                (0.9, 0.7, 0.5),  # Warm (sunset)\n                (1.0, 1.0, 1.0)   # Cool white\n            ))\n\ndef advanced_lighting_randomization():\n    \"\"\"Advanced lighting randomization with multiple light sources\"\"\"\n\n    # Primary directional light (sun)\n    def randomize_sun():\n        with rep.randomizer:\n            sun = rep.get.light(prim_paths=['/World/Sun'])\n            with sun:\n                # Time of day simulation\n                time_of_day = rep.distribution.choice([\n                    'sunrise', 'morning', 'noon', 'afternoon', 'sunset', 'night'\n                ])\n\n                # Position based on time of day\n                position_map = {\n                    'sunrise': (30, 10, 0),\n                    'morning': (60, 45, 30),\n                    'noon': (0, 90, 0),\n                    'afternoon': (-60, 45, -30),\n                    'sunset': (-30, 10, 180),\n                    'night': (0, -60, 0)  # Below horizon\n                }\n\n                # Apply position based on time\n                # (This would be implemented with conditional distributions)\n\n    # Ambient lighting\n    def randomize_ambient():\n        with rep.randomizer:\n            ambient = rep.get.light(prim_paths=['/World/Ambient'])\n            with ambient:\n                rep.light.intensity(rep.distribution.uniform(0.1, 0.8))\n                rep.light.color(rep.distribution.uniform(\n                    (0.2, 0.2, 0.4),  # Blueish night\n                    (0.9, 0.9, 0.8)   # Warm day\n                ))\n\n    return randomize_sun, randomize_ambient\n"})}),"\n",(0,a.jsx)(e.h3,{id:"environmental-lighting",children:"Environmental Lighting"}),"\n",(0,a.jsx)(e.p,{children:"Randomizing environment maps and dome lighting:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def randomize_environment_lighting():\n    \"\"\"Randomize environment dome lighting\"\"\"\n\n    # Create a set of different environment maps\n    env_maps = [\n        \"path/to/clear_sky.exr\",\n        \"path/to/cloudy_sky.exr\",\n        \"path/to/urban_sunset.exr\",\n        \"path/to/forest.exr\",\n        \"path/to/indoor.exr\"\n    ]\n\n    with rep.randomizer:\n        dome_lights = rep.get.light(\n            prim_paths=['/World/DomeLight'],\n            light_types=['DomeLight']\n        )\n\n        with dome_lights:\n            # Randomize environment map\n            rep.light.environment_texture(\n                rep.distribution.choice(env_maps)\n            )\n\n            # Randomize dome light intensity\n            rep.light.intensity(rep.distribution.uniform(0.5, 2.0))\n\n            # Randomize dome rotation for different lighting directions\n            rep.modify.pose(\n                rotation=rep.distribution.uniform(\n                    (0, 0, 0), (0, 360, 0)  # Rotate around Y axis\n                )\n            )\n\ndef weather_based_lighting():\n    \"\"\"Apply lighting based on weather conditions\"\"\"\n\n    weather_configs = {\n        'clear': {\n            'sun_intensity': (1000, 1500),\n            'ambient_intensity': (0.2, 0.3),\n            'fog_density': (0.0, 0.001)\n        },\n        'cloudy': {\n            'sun_intensity': (500, 800),\n            'ambient_intensity': (0.5, 0.7),\n            'fog_density': (0.001, 0.005)\n        },\n        'foggy': {\n            'sun_intensity': (200, 400),\n            'ambient_intensity': (0.3, 0.5),\n            'fog_density': (0.005, 0.02)\n        },\n        'rainy': {\n            'sun_intensity': (100, 300),\n            'ambient_intensity': (0.4, 0.6),\n            'fog_density': (0.002, 0.01)\n        }\n    }\n\n    # This would be implemented with conditional randomization\n    # based on the selected weather condition\n"})}),"\n",(0,a.jsx)(e.h2,{id:"object-pose-randomization",children:"Object Pose Randomization"}),"\n",(0,a.jsx)(e.h3,{id:"position-and-orientation-randomization",children:"Position and Orientation Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Randomizing the 6-degree-of-freedom pose of objects in the scene:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def randomize_object_poses():\n    """Randomize object positions and orientations"""\n\n    with rep.randomizer:\n        objects = rep.get.prim_with_property(\n            prim_types=[\'Mesh\'],\n            property_name=\'physics\'\n        )\n\n        with objects:\n            # Randomize position within a bounding volume\n            rep.modify.pose(\n                position=rep.distribution.uniform(\n                    (-10, 0, -10),   # Min bounds\n                    (10, 5, 10)      # Max bounds\n                )\n            )\n\n            # Randomize orientation (rotation)\n            rep.modify.pose(\n                rotation=rep.distribution.uniform(\n                    (-180, -180, -180),  # Min rotations\n                    (180, 180, 180)      # Max rotations\n                )\n            )\n\ndef constrained_pose_randomization():\n    """Randomize poses with physical constraints"""\n\n    def place_objects_on_surfaces():\n        """Place objects on valid surfaces"""\n        with rep.randomizer:\n            objects = rep.get.prim_with_property(\n                prim_types=[\'Mesh\'],\n                property_name=\'physics\'\n            )\n\n            # Define valid placement surfaces\n            surfaces = rep.get.prim_with_property(\n                prim_paths=[\'/World/Ground\', \'/World/Tables/*\']\n            )\n\n            # Place objects on these surfaces with height variation\n            rep.modify.pose(\n                position=rep.distribution.surface_placement(\n                    surfaces,\n                    height_offset=rep.distribution.uniform(0.1, 0.5)\n                )\n            )\n\n    def maintain_stability():\n        """Ensure objects are placed stably"""\n        with rep.randomizer:\n            objects = rep.get.prim_with_property(\n                prim_types=[\'Mesh\']\n            )\n\n            # Apply constraints to ensure stable placement\n            rep.randomizer.stability_constraint(\n                min_stability=0.8,\n                max_tilt_angle=30\n            )\n\n    return place_objects_on_surfaces, maintain_stability\n'})}),"\n",(0,a.jsx)(e.h3,{id:"object-distribution-patterns",children:"Object Distribution Patterns"}),"\n",(0,a.jsx)(e.p,{children:"Creating different spatial distributions for objects:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def create_object_distributions():\n    """Create different spatial distributions for objects"""\n\n    def uniform_distribution():\n        """Uniform random distribution"""\n        return rep.distribution.uniform(\n            (-10, 0, -10), (10, 0, 10)\n        )\n\n    def gaussian_distribution(center, std_dev):\n        """Gaussian distribution around a center point"""\n        return (\n            rep.distribution.normal(center[0], std_dev),\n            rep.distribution.normal(center[1], std_dev),\n            rep.distribution.normal(center[2], std_dev)\n        )\n\n    def clustered_distribution():\n        """Clustered distribution with multiple centers"""\n        centers = [\n            (2, 0, 2),\n            (-2, 0, -2),\n            (0, 0, 5)\n        ]\n\n        # Choose a random center, then add small offset\n        chosen_center = rep.distribution.choice(centers)\n        offset = rep.distribution.uniform((-1, 0, -1), (1, 0, 1))\n\n        return (\n            chosen_center[0] + offset[0],\n            chosen_center[1] + offset[1],\n            chosen_center[2] + offset[2]\n        )\n\n    def grid_distribution(grid_size, spacing):\n        """Grid-based distribution"""\n        x_idx = rep.distribution.uniform(0, grid_size[0]-1)\n        z_idx = rep.distribution.uniform(0, grid_size[1]-1)\n\n        return (\n            x_idx * spacing[0] - (grid_size[0]-1) * spacing[0] / 2,\n            0,\n            z_idx * spacing[1] - (grid_size[1]-1) * spacing[1] / 2\n        )\n\ndef apply_distribution_based_randomization():\n    """Apply different distributions to different object types"""\n\n    # Different object types may have different spatial preferences\n    object_distributions = {\n        \'vehicles\': lambda: create_object_distributions().uniform_distribution(),\n        \'pedestrians\': lambda: create_object_distributions().gaussian_distribution((0,0,0), 3),\n        \'obstacles\': lambda: create_object_distributions().clustered_distribution(),\n        \'decorations\': lambda: create_object_distributions().grid_distribution((5,5), (2,2))\n    }\n\n    for obj_type, distribution_func in object_distributions.items():\n        with rep.randomizer:\n            objects = rep.get.prim_with_property(\n                prim_paths=[f\'/World/{obj_type.title()}/*\']\n            )\n\n            with objects:\n                pos_distribution = distribution_func()\n                rep.modify.pose(position=pos_distribution)\n'})}),"\n",(0,a.jsx)(e.h2,{id:"camera-parameter-variations",children:"Camera Parameter Variations"}),"\n",(0,a.jsx)(e.h3,{id:"intrinsic-parameter-randomization",children:"Intrinsic Parameter Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Randomizing camera intrinsic parameters that affect the image formation:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def randomize_camera_intrinsics():\n    \"\"\"Randomize camera intrinsic parameters\"\"\"\n\n    with rep.randomizer:\n        cameras = rep.get.camera(prim_paths=['/World/Cameras/*'])\n\n        with cameras:\n            # Randomize focal length (affects field of view)\n            # Typical range: 18mm (wide) to 200mm (telephoto)\n            rep.camera.focal_length(rep.distribution.uniform(18, 85))\n\n            # Randomize sensor size\n            rep.camera.sensor_width(rep.distribution.uniform(24, 36))  # mm\n            rep.camera.sensor_height(rep.distribution.uniform(16, 24))  # mm\n\n            # Randomize principal point offset (sensor alignment)\n            rep.camera.principal_point_x(\n                rep.distribution.uniform(-0.1, 0.1)  # normalized\n            )\n            rep.camera.principal_point_y(\n                rep.distribution.uniform(-0.1, 0.1)  # normalized\n            )\n\ndef apply_realistic_camera_constraints():\n    \"\"\"Apply realistic constraints to camera parameters\"\"\"\n\n    # Different camera types have different parameter ranges\n    camera_configs = {\n        'webcam': {\n            'focal_range': (2, 8),  # Short focal length\n            'resolution_range': [(640, 480), (1280, 720)],\n            'distortion_range': (0.0, 0.1)\n        },\n        'dslr': {\n            'focal_range': (18, 200),\n            'resolution_range': [(1920, 1080), (4000, 3000)],\n            'distortion_range': (0.0, 0.05)\n        },\n        'industrial': {\n            'focal_range': (6, 25),\n            'resolution_range': [(1280, 1024), (2448, 2048)],\n            'distortion_range': (0.0, 0.02)\n        }\n    }\n\n    for cam_type, config in camera_configs.items():\n        with rep.randomizer:\n            cameras = rep.get.camera(prim_paths=[f'/World/Cameras/{cam_type}/*'])\n\n            with cameras:\n                rep.camera.focal_length(\n                    rep.distribution.uniform(\n                        config['focal_range'][0],\n                        config['focal_range'][1]\n                    )\n                )\n\n                # For now, just focal length; resolution is typically fixed per camera\n"})}),"\n",(0,a.jsx)(e.h3,{id:"extrinsic-parameter-randomization",children:"Extrinsic Parameter Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Randomizing camera position and orientation:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def randomize_camera_extrinsics():\n    """Randomize camera extrinsic parameters (position/orientation)"""\n\n    with rep.randomizer:\n        cameras = rep.get.camera(prim_paths=[\'/World/Cameras/*\'])\n\n        with cameras:\n            # Randomize camera position\n            rep.modify.pose(\n                position=rep.distribution.uniform(\n                    (-5, 1, -5),   # Min bounds\n                    (5, 3, 5)      # Max bounds\n                )\n            )\n\n            # Randomize camera orientation\n            rep.modify.pose(\n                rotation=rep.distribution.uniform(\n                    (-30, -180, -10),  # Min rotations\n                    (30, 180, 10)      # Max rotations\n                )\n            )\n\ndef robot_camera_randomization():\n    """Randomize cameras mounted on robots"""\n\n    # For robot-mounted cameras, randomize relative to robot\n    def randomize_robot_cameras():\n        with rep.randomizer:\n            # Get cameras attached to robots\n            robot_cameras = rep.get.camera(\n                prim_paths=[\'/World/Robots/*/Camera\']\n            )\n\n            with robot_cameras:\n                # Randomize relative position to robot\n                rep.modify.pose(\n                    position=rep.distribution.uniform(\n                        (-0.5, 0.5, -0.5),   # Relative to robot\n                        (0.5, 1.5, 0.5)\n                    )\n                )\n\n                # Randomize relative orientation\n                rep.modify.pose(\n                    rotation=rep.distribution.uniform(\n                        (-10, -45, -10),     # Looking forward with variation\n                        (10, 45, 10)\n                    )\n                )\n\n    # For static cameras, randomize in environment\n    def randomize_static_cameras():\n        with rep.randomizer:\n            static_cameras = rep.get.camera(\n                prim_paths=[\'/World/StaticCameras/*\']\n            )\n\n            with static_cameras:\n                # Place on walls, ceilings, or mounted positions\n                mount_points = rep.get.prim_with_property(\n                    prim_paths=[\'/World/MountPoints/*\']\n                )\n\n                rep.modify.pose(\n                    position=rep.distribution.surface_placement(\n                        mount_points,\n                        height_offset=rep.distribution.uniform(2, 4)\n                    )\n                )\n\n    return randomize_robot_cameras, randomize_static_cameras\n'})}),"\n",(0,a.jsx)(e.h2,{id:"statistical-distribution-strategies",children:"Statistical Distribution Strategies"}),"\n",(0,a.jsx)(e.h3,{id:"uniform-vs-non-uniform-distributions",children:"Uniform vs Non-Uniform Distributions"}),"\n",(0,a.jsx)(e.p,{children:"Different distributions serve different purposes in domain randomization:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def distribution_strategies():\n    """Different statistical distribution strategies"""\n\n    # Uniform distribution - covers full range evenly\n    def uniform_strategy():\n        """Use uniform distribution for maximum variation"""\n        return rep.distribution.uniform(0.1, 0.9)\n\n    # Normal distribution - focuses on central values with outliers\n    def normal_strategy(mean=0.5, std=0.1):\n        """Use normal distribution for realistic clustering"""\n        return rep.distribution.normal(mean, std)\n\n    # Exponential distribution - emphasizes one end of range\n    def exponential_strategy(rate=1.0):\n        """Use exponential for rare events"""\n        return rep.distribution.exponential(rate)\n\n    # Beta distribution - flexible shape between 0 and 1\n    def beta_strategy(alpha=2, beta=2):\n        """Use beta distribution for flexible shapes"""\n        return rep.distribution.beta(alpha, beta)\n\ndef adaptive_distribution_randomization():\n    """Adaptively adjust distributions based on training progress"""\n\n    # This would be implemented as a more sophisticated system\n    # that adjusts randomization based on model performance\n\n    class AdaptiveRandomizer:\n        def __init__(self):\n            self.performance_history = []\n            self.current_distribution_params = {\n                \'lighting\': (0.5, 1.5),  # mean, std\n                \'materials\': (0.1, 0.9), # min, max\n                \'objects\': 10            # count\n            }\n\n        def update_parameters(self, performance_metric):\n            """Update distribution parameters based on performance"""\n            if performance_metric > 0.9:  # Model is doing well\n                # Increase randomization difficulty\n                self.current_distribution_params[\'materials\'] = (0.05, 0.95)\n            elif performance_metric < 0.7:  # Model is struggling\n                # Decrease randomization difficulty\n                self.current_distribution_params[\'materials\'] = (0.2, 0.8)\n\n    return AdaptiveRandomizer()\n'})}),"\n",(0,a.jsx)(e.h3,{id:"correlated-parameter-randomization",children:"Correlated Parameter Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Sometimes parameters should be correlated to maintain physical plausibility:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def correlated_randomization():\n    \"\"\"Randomize parameters that should be correlated\"\"\"\n\n    def weather_correlation():\n        \"\"\"Correlate lighting, fog, and color temperature\"\"\"\n\n        # Define weather conditions with correlated parameters\n        weather_scenarios = [\n            {\n                'lighting': {'intensity': (800, 1200), 'color': (0.9, 0.9, 1.0)},\n                'fog': {'density': (0.0, 0.001), 'color': (1.0, 1.0, 1.0)},\n                'temperature': 6500  # Clear day\n            },\n            {\n                'lighting': {'intensity': (400, 700), 'color': (0.8, 0.8, 0.9)},\n                'fog': {'density': (0.001, 0.005), 'color': (0.8, 0.8, 0.9)},\n                'temperature': 5500  # Overcast\n            },\n            {\n                'lighting': {'intensity': (200, 400), 'color': (0.6, 0.6, 0.8)},\n                'fog': {'density': (0.005, 0.02), 'color': (0.7, 0.7, 0.8)},\n                'temperature': 4500  # Foggy/rainy\n            }\n        ]\n\n        # Select weather scenario\n        scenario = rep.distribution.choice(weather_scenarios)\n\n        # Apply correlated parameters\n        with rep.randomizer:\n            # Apply to lighting\n            lights = rep.get.light()\n            with lights:\n                rep.light.intensity(\n                    rep.distribution.uniform(\n                        scenario['lighting']['intensity'][0],\n                        scenario['lighting']['intensity'][1]\n                    )\n                )\n                rep.light.color(\n                    scenario['lighting']['color']\n                )\n\n    def material_correlation():\n        \"\"\"Correlate material properties for realism\"\"\"\n\n        # Metal objects should have high metallic and low roughness\n        # Plastic objects should have low metallic and variable roughness\n        # etc.\n        pass\n\n    return weather_correlation, material_correlation\n"})}),"\n",(0,a.jsx)(e.h2,{id:"implementation-best-practices",children:"Implementation Best Practices"}),"\n",(0,a.jsx)(e.h3,{id:"progressive-domain-randomization",children:"Progressive Domain Randomization"}),"\n",(0,a.jsx)(e.p,{children:"Start with limited randomization and gradually increase:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:"def progressive_domain_randomization():\n    \"\"\"Implement progressive domain randomization\"\"\"\n\n    class ProgressiveRandomizer:\n        def __init__(self):\n            self.stage = 0\n            self.stages = [\n                # Stage 0: Minimal randomization (base case)\n                {\n                    'lighting_variation': 0.1,\n                    'material_variation': 0.1,\n                    'object_variation': 0.1,\n                    'camera_variation': 0.05\n                },\n                # Stage 1: Moderate randomization\n                {\n                    'lighting_variation': 0.3,\n                    'material_variation': 0.3,\n                    'object_variation': 0.3,\n                    'camera_variation': 0.1\n                },\n                # Stage 2: High randomization\n                {\n                    'lighting_variation': 0.6,\n                    'material_variation': 0.6,\n                    'object_variation': 0.5,\n                    'camera_variation': 0.2\n                },\n                # Stage 3: Maximum randomization\n                {\n                    'lighting_variation': 1.0,\n                    'material_variation': 1.0,\n                    'object_variation': 0.8,\n                    'camera_variation': 0.3\n                }\n            ]\n\n        def get_current_params(self):\n            \"\"\"Get parameters for current stage\"\"\"\n            return self.stages[self.stage]\n\n        def advance_stage(self, performance_threshold=0.85):\n            \"\"\"Advance to next stage if performance is good\"\"\"\n            if self.stage < len(self.stages) - 1:\n                self.stage += 1\n                print(f\"Advancing to domain randomization stage {self.stage}\")\n\n        def apply_randomization(self):\n            \"\"\"Apply randomization based on current stage\"\"\"\n            params = self.get_current_params()\n\n            # Apply randomization with current parameters\n            # This would use the randomization functions defined earlier\n            # but scaled by the variation factors\n            pass\n\n    return ProgressiveRandomizer()\n"})}),"\n",(0,a.jsx)(e.h3,{id:"validation-and-monitoring",children:"Validation and Monitoring"}),"\n",(0,a.jsx)(e.p,{children:"Monitor the effectiveness of domain randomization:"}),"\n",(0,a.jsx)(e.pre,{children:(0,a.jsx)(e.code,{className:"language-python",children:'def validation_and_monitoring():\n    """Validate and monitor domain randomization effectiveness"""\n\n    class RandomizationValidator:\n        def __init__(self):\n            self.metrics = {\n                \'diversity_score\': [],\n                \'realism_score\': [],\n                \'training_stability\': [],\n                \'sim2real_gap\': []\n            }\n\n        def calculate_diversity_score(self, dataset):\n            """Calculate how diverse the generated data is"""\n            # Measure variation in key parameters\n            # Compare to baseline diversity\n            pass\n\n        def assess_realism(self, synthetic_data, real_data):\n            """Assess how realistic the synthetic data appears"""\n            # Use domain classifier to measure realism\n            # Compare statistical properties\n            pass\n\n        def monitor_training_stability(self, model_performance):\n            """Monitor if randomization is helping or hurting training"""\n            # Check for training instability due to excessive randomization\n            # Adjust randomization if needed\n            pass\n\n        def measure_sim2real_gap(self, sim_performance, real_performance):\n            """Measure the gap between simulation and real performance"""\n            gap = abs(sim_performance - real_performance)\n            return gap\n\n    return RandomizationValidator()\n'})}),"\n",(0,a.jsx)(e.h2,{id:"exercises",children:"Exercises"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Exercise 1"}),": Implement a domain randomization system for a warehouse robotics scenario that varies lighting, materials, and object positions while maintaining physical plausibility."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Exercise 2"}),": Create a progressive domain randomization pipeline that starts with minimal variations and gradually increases complexity based on model performance."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Exercise 3"}),": Design a correlated parameter randomization system where lighting, weather, and material properties are varied together to maintain scene coherence."]}),"\n"]}),"\n",(0,a.jsxs)(e.li,{children:["\n",(0,a.jsxs)(e.p,{children:[(0,a.jsx)(e.strong,{children:"Exercise 4"}),": Develop a validation system that monitors the effectiveness of domain randomization and adjusts parameters based on sim-to-real transfer performance."]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"best-practices",children:"Best Practices"}),"\n",(0,a.jsx)(e.h3,{id:"domain-randomization-best-practices",children:"Domain Randomization Best Practices"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Start Conservative"}),": Begin with limited randomization and gradually increase"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Maintain Plausibility"}),": Ensure randomized parameters remain physically plausible"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Monitor Performance"}),": Track the impact of randomization on model performance"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Use Correlations"}),": Randomize related parameters together when appropriate"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Validate Results"}),": Regularly validate that randomization improves real-world performance"]}),"\n"]}),"\n",(0,a.jsx)(e.h3,{id:"parameter-selection-best-practices",children:"Parameter Selection Best Practices"}),"\n",(0,a.jsxs)(e.ol,{children:["\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Domain Knowledge"}),": Use domain knowledge to identify important parameters"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Sensitivity Analysis"}),": Test which parameters most affect sim-to-real transfer"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Real-World Ranges"}),": Base parameter ranges on real-world observations"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Physical Constraints"}),": Respect physical constraints and relationships"]}),"\n",(0,a.jsxs)(e.li,{children:[(0,a.jsx)(e.strong,{children:"Task Relevance"}),": Focus on parameters relevant to the specific task"]}),"\n"]}),"\n",(0,a.jsx)(e.h2,{id:"conclusion",children:"Conclusion"}),"\n",(0,a.jsx)(e.p,{children:"Domain randomization is a powerful technique for improving the sim-to-real transfer of machine learning models in robotics applications. By systematically varying simulation parameters across wide ranges, it forces models to learn robust features that generalize across different conditions."}),"\n",(0,a.jsx)(e.p,{children:"The key to effective domain randomization is finding the right balance between variation and plausibility. Too little variation and the model won't be robust to real-world conditions; too much variation and the model may fail to learn meaningful features. Progressive approaches that start with limited randomization and increase complexity based on performance provide a good middle ground."}),"\n",(0,a.jsx)(e.p,{children:"As we continue through this module, we'll explore how these domain randomization techniques integrate with the broader synthetic data generation pipeline and how they contribute to creating effective training datasets for robotics applications. The combination of systematic variation, realistic constraints, and performance monitoring makes domain randomization an essential tool in the synthetic data generation toolkit."})]})}function m(n={}){const{wrapper:e}={...(0,r.R)(),...n.components};return e?(0,a.jsx)(e,{...n,children:(0,a.jsx)(c,{...n})}):c(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(n){const e=t.useContext(r);return t.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function s(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(a):n.components||a:o(n.components),t.createElement(r.Provider,{value:e},n.children)}}}]);